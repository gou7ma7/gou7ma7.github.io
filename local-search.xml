<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>post</title>
    <link href="/2026/02/09/book/@2026_How_Dare_You/"/>
    <url>/2026/02/09/book/@2026_How_Dare_You/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>AI agent 编排工具 Goose Desktop 持续出现 404 错误的长期未解决 Issue</title>
    <link href="/2026/02/07/devops/@2026_execute_in_goose/"/>
    <url>/2026/02/07/devops/@2026_execute_in_goose/</url>
    
    <content type="html"><![CDATA[<h1 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h1><p>这几天我在 Windows（以及 Linux）上用 Goose <strong>Desktop GUI</strong> 用 <code>Other Providers</code> 的 Azure OpenAI 遇到一个问题：<strong>GUI 里填的 LLM 地址&#x2F;配置看起来完全正确，但一用就报 404</strong>。</p><span id="more"></span><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">Could <span class="hljs-keyword">not</span> contact provider<br>Failed <span class="hljs-keyword">to</span> <span class="hljs-keyword">fetch</span> models <span class="hljs-keyword">for</span> azure_openai: Provider error: Request failed: Resource <span class="hljs-keyword">not</span> <span class="hljs-built_in">found</span> (<span class="hljs-number">404</span>): Resource <span class="hljs-keyword">not</span> <span class="hljs-built_in">found</span><br><span class="hljs-keyword">Check</span> your provider <span class="hljs-keyword">configuration</span> <span class="hljs-keyword">in</span> Settings → Providers<br></code></pre></td></tr></table></figure><p>更离谱的是 —— 同样的 Azure OpenAI 服务：</p><ul><li>用 <code>curl</code> 直接调用没问题</li><li>用 VScode 连该 API 也没问题</li><li>装了 Goose CLI 之后，Desktop 反而突然好了，甚至还能看到 CLI 刚跑出来的 session</li><li>换多台机器，不同操作系统验证过</li></ul><p>这整件事看起来是：<strong>Goose Desktop 本地的 goosed 后端无法正确的加载</strong>。</p><p>相关 Issue（同类症状）：<a href="https://github.com/block/goose/issues/3571"><code>block/goose#3571</code></a></p><hr><h2 id="关键事实：Desktop-不是“GUI-直连云端”，而是-“GUI-→-本地-goosed-→-云端”"><a href="#关键事实：Desktop-不是“GUI-直连云端”，而是-“GUI-→-本地-goosed-→-云端”" class="headerlink" title="关键事实：Desktop 不是“GUI 直连云端”，而是 “GUI → 本地 goosed → 云端”"></a>关键事实：Desktop 不是“GUI 直连云端”，而是 “GUI → 本地 goosed → 云端”</h2><p>Goose Desktop 运行时会在本机拉起一个 Rust 后端进程 <code>goosed</code>，GUI 只是通过 <code>127.0.0.1:&lt;port&gt;</code> 调它的 API，再由 <code>goosed</code> 去请求供应商。</p><p>所以“看起来像 LLM 404”的错误，至少要拆成三类看：</p><ul><li><strong>本地 goosed API 返回的 4xx&#x2F;5xx</strong>（例如鉴权、路由、版本不匹配）</li><li><strong>goosed 转发到供应商后，供应商返回的 4xx&#x2F;5xx</strong></li><li><strong>goosed 在后台做“拉模型列表&#x2F;探活”失败</strong>（跟真正发 <code>chat/completions</code> 不是一回事）</li></ul><h1 id="试验过程"><a href="#试验过程" class="headerlink" title="试验过程"></a>试验过程</h1><h2 id="1）Desktop-里“看起来任何-provider-都-404”"><a href="#1）Desktop-里“看起来任何-provider-都-404”" class="headerlink" title="1）Desktop 里“看起来任何 provider 都 404”"></a>1）Desktop 里“看起来任何 provider 都 404”</h2><p>GUI 提示经常是：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nix">Request <span class="hljs-params">failed:</span> Request failed <span class="hljs-keyword">with</span> <span class="hljs-params">status:</span> <span class="hljs-number">404</span> Not Found<br></code></pre></td></tr></table></figure><p>日志里则会看到类似（注意这个位置经常出现在 Desktop 的 <code>main.log</code> 里，因为它会把 goosed 的 stderr 转存进去）：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">WARN goose<span class="hljs-type">::providers</span><span class="hljs-type">::openai_compatible</span>: Provider request failed <span class="hljs-keyword">with</span> status: <span class="hljs-number">404</span> <span class="hljs-literal">Not</span> Found <span class="hljs-params">...</span> <span class="hljs-string">&quot;Resource not found&quot;</span><br></code></pre></td></tr></table></figure><p>这跟 issue <a href="https://github.com/block/goose/issues/3571"><code>block/goose#3571</code></a> 的描述非常像：同一套 key&#x2F;模型用 curl 能通，但 Desktop 里持续 404。</p><hr><h2 id="2）curl-PowerShell-直连-Azure：服务是好的"><a href="#2）curl-PowerShell-直连-Azure：服务是好的" class="headerlink" title="2）curl &#x2F; PowerShell 直连 Azure：服务是好的"></a>2）curl &#x2F; PowerShell 直连 Azure：服务是好的</h2><p>以 Azure OpenAI 为例，我这边 endpoint 大概长这样：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">https:</span><span class="hljs-comment">//&lt;portal&gt;.azure.com</span><br></code></pre></td></tr></table></figure><p>可以直接 200 并返回回复。</p><p>结论：<strong>Azure chat&#x2F;completions 本身是通的</strong>。</p><hr><h2 id="3）-省略其中-AI-带着我逛了至少-4h-的完全方向都错误的过程"><a href="#3）-省略其中-AI-带着我逛了至少-4h-的完全方向都错误的过程" class="headerlink" title="3） 省略其中 AI 带着我逛了至少 4h 的完全方向都错误的过程"></a>3） 省略其中 AI 带着我逛了至少 4h 的完全方向都错误的过程</h2><h1 id="根本原因"><a href="#根本原因" class="headerlink" title="根本原因"></a>根本原因</h1><p>不知道是不是像我这样用自带 LLM 的人太少，半年都没人定位到根本原因（Root Cause）；</p><p>三天前维护者还说拖太久了，直接把 issue 关了，实在离谱。</p><p><a href="https://github.com/block/goose/issues/3571#issuecomment-3871651227">https://github.com/block/goose/issues/3571#issuecomment-3871651227</a></p><p>上面是我找到的绕过办法。本质原因是：Desktop 在写入 config.yml 时比 CLI 少写了 <code>GOOSE_PROVIDER</code> 和 <code>GOOSE_MODEL</code> 两个字段，导致程序找不到 MODEL；</p><p>而选择 MODEL 时又必须先验证成功才能把配置写回文件——于是形成死循环，永远连不上。</p><p>因此只有先安装 CLI 并在其中配好，才能正常用。</p><div class="note note-info">            <p><strong>更新</strong>：官方在 <strong>v1.24.0</strong>（2026-02-12）中修复了该问题。具体改动见 PR <a href="https://github.com/block/goose/pull/7034">fix(providers): Azure OpenAI model listing 404 during configure #7034</a>，Release 说明见 <a href="https://github.com/block/goose/releases/tag/v1.24.0">v1.24.0 · block&#x2F;goose</a>。</p><p>Desktop 配置 Azure 时不应再出现“拉模型列表 404”导致的死循环。</p>          </div><hr><h1 id="开盖研究"><a href="#开盖研究" class="headerlink" title="开盖研究"></a>开盖研究</h1><p>这一章开始“开盖”——不再盯着 GUI 的报错，而是<strong>把 goosed 从源码编出来，直接用 API 证明它到底有没有成功连到 Azure</strong>。</p><h2 id="1）在-Windows-上把后端编出来（release）"><a href="#1）在-Windows-上把后端编出来（release）" class="headerlink" title="1）在 Windows 上把后端编出来（release）"></a>1）在 Windows 上把后端编出来（release）</h2><p>由于从来也没用过 Rust，且有近 20年 没在 Windows 上运行编译型语言，以下路径也均为 AI建议 先走试试。</p><p>我用的路径是“纯 Windows + pwsh + MSVC toolchain”，核心是两件事：</p><ul><li>Rust 工具链（rustup&#x2F;cargo）</li><li>VS Build Tools（提供 <code>link.exe</code>）</li></ul><p>然后编后端：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">cargo build <span class="hljs-literal">--release</span> <span class="hljs-literal">-p</span> goose<span class="hljs-literal">-server</span><br></code></pre></td></tr></table></figure><p>产物默认在：</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs llvm"><span class="hljs-keyword">target</span>\<span class="hljs-keyword">release</span>\goosed.exe<br></code></pre></td></tr></table></figure><h2 id="2）启动-goosed，并固定一个-X-Secret-Key"><a href="#2）启动-goosed，并固定一个-X-Secret-Key" class="headerlink" title="2）启动 goosed，并固定一个 X-Secret-Key"></a>2）启动 goosed，并固定一个 X-Secret-Key</h2><p>goosed 除 <code>/status</code> 外的大多数 API 都需要 <code>X-Secret-Key</code>。本地跑建议固定一个：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$env:GOOSE_SERVER__SECRET_KEY</span> = <span class="hljs-string">&quot;dev-secret&quot;</span><br>.\target\release\goosed.exe agent<br></code></pre></td></tr></table></figure><p>验证 health：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-built_in">irm</span> http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3000</span>/status<br></code></pre></td></tr></table></figure><h2 id="3）验证：goosed-是否确实读取了-config-yaml-里的-Azure-配置"><a href="#3）验证：goosed-是否确实读取了-config-yaml-里的-Azure-配置" class="headerlink" title="3）验证：goosed 是否确实读取了 config.yaml 里的 Azure 配置"></a>3）验证：goosed 是否确实读取了 config.yaml 里的 Azure 配置</h2><p>用 goosed 的 <code>/config</code> 直接读（需要 <code>X-Secret-Key</code>）：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$h</span>=<span class="hljs-selector-tag">@</span>&#123; <span class="hljs-string">&quot;X-Secret-Key&quot;</span>=<span class="hljs-string">&quot;dev-secret&quot;</span> &#125;<br><span class="hljs-variable">$cfg</span> = <span class="hljs-built_in">irm</span> http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3000</span>/config <span class="hljs-literal">-Headers</span> <span class="hljs-variable">$h</span><br><span class="hljs-variable">$cfg</span>.config.AZURE_OPENAI_ENDPOINT<br><span class="hljs-variable">$cfg</span>.config.AZURE_OPENAI_API_VERSION<br><span class="hljs-variable">$cfg</span>.config.AZURE_OPENAI_DEPLOYMENT_NAME<br></code></pre></td></tr></table></figure><p>这一步能确认：<strong>配置确实被 goosed 读取到了</strong>。</p><h2 id="4）最关键：验证-goosed-能否真实调用-Azure（不是-status-那种空壳）"><a href="#4）最关键：验证-goosed-能否真实调用-Azure（不是-status-那种空壳）" class="headerlink" title="4）最关键：验证 goosed 能否真实调用 Azure（不是 &#x2F;status 那种空壳）"></a>4）最关键：验证 goosed 能否真实调用 Azure（不是 &#x2F;status 那种空壳）</h2><p>我用的是一条“完整链路”：</p><ol><li><code>POST /agent/start</code> 创建 session</li><li><code>POST /agent/update_provider</code> 设置 <code>azure_openai + gpt-4.1</code></li><li><code>POST /reply</code> 发一条消息，看 SSE 是否出现 <code>Message</code> 事件</li></ol><p>为什么这能作为“硬证据”？</p><ul><li><code>/reply</code> 是真正会触发 <code>agent.reply()</code> 的路径</li><li>provider 会走到 <code>OpenAiCompatibleProvider</code> 的 <code>chat/completions</code></li><li>如果没连到供应商，通常会返回 <code>Error</code> 事件或直接 5xx</li></ul><p>后端链路代码入口：</p><ul><li><code>/reply</code> handler：<code>crates/goose-server/src/routes/reply.rs</code><ul><li><a href="https://github.com/block/goose/blob/main/crates/goose-server/src/routes/reply.rs">https://github.com/block/goose/blob/main/crates/goose-server/src/routes/reply.rs</a></li></ul></li></ul><p>关键片段（摘录）：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// crates/goose-server/src/routes/reply.rs</span><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">stream</span> = agent.<span class="hljs-title function_ invoke__">reply</span>(user_message, session_config, <span class="hljs-title function_ invoke__">Some</span>(cancel_token)).<span class="hljs-keyword">await</span>?;<br><span class="hljs-comment">// 然后把 AgentEvent::Message 作为 SSE 输出给客户端</span><br></code></pre></td></tr></table></figure><p>而真正发出 <code>chat/completions</code> 的位置是：</p><ul><li><code>crates/goose/src/providers/openai_compatible.rs</code><ul><li><a href="https://github.com/block/goose/blob/main/crates/goose/src/providers/openai_compatible.rs">https://github.com/block/goose/blob/main/crates/goose/src/providers/openai_compatible.rs</a></li></ul></li></ul><p>关键片段（摘录）：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">completions_path</span> = <span class="hljs-built_in">format!</span>(<span class="hljs-string">&quot;&#123;&#125;chat/completions&quot;</span>, <span class="hljs-keyword">self</span>.completions_prefix);<br><span class="hljs-keyword">let</span> <span class="hljs-variable">resp</span> = <span class="hljs-keyword">self</span>.api_client.<span class="hljs-title function_ invoke__">response_post</span>(session_id, &amp;completions_path, &amp;payload).<span class="hljs-keyword">await</span>?;<br></code></pre></td></tr></table></figure><h3 id="我实际用来验证的-PowerShell（可复用）"><a href="#我实际用来验证的-PowerShell（可复用）" class="headerlink" title="我实际用来验证的 PowerShell（可复用）"></a>我实际用来验证的 PowerShell（可复用）</h3><p>如果你想完整照抄一遍验证，可以参考文末附录里的 PowerShell 脚本（负责创建 session、设置 <code>azure_openai + gpt-4.1</code> 并调用 <code>/reply</code>，确认 SSE 里出现 <code>Message</code> 事件）。</p><h2 id="5）Azure-列模型-404：根因与修复"><a href="#5）Azure-列模型-404：根因与修复" class="headerlink" title="5）Azure 列模型 404：根因与修复"></a>5）Azure 列模型 404：根因与修复</h2><p><strong>根因就是列模型时 URL 拼错了</strong>：旧代码把 deployment 塞进了所有请求共用的 host（如 <code>endpoint/openai/deployments/gpt-4.1</code>），导致列模型也发成 <code>GET .../deployments/gpt-4.1/models</code>，而 Azure 只认 <code>GET .../openai/models</code>，所以 404。</p><p><strong>官方修法（PR #7034）</strong>：把 URL 拼对——列模型用 <code>&#123;endpoint&#125;/openai/models</code>，发对话时才在路径前加 <code>deployments/&#123;name&#125;/</code>（见 <code>openai_compatible.rs</code> 的 <code>completions_prefix</code>），各用各的路径，404 消失。</p><h3 id="参考实现（我本地的-patch-思路）"><a href="#参考实现（我本地的-patch-思路）" class="headerlink" title="参考实现（我本地的 patch 思路）"></a>参考实现（我本地的 patch 思路）</h3><blockquote><p>说明：下面是“修复方向”的代码形态。你也可以把它理解为：<strong>Azure 既然不支持 <code>/openai/models</code>，那就别去打它，返回空列表让 UI 手输 deployment name</strong>。</p></blockquote><p>1）服务端：Azure 直接返回空列表，避免触发 <code>GET /openai/models</code></p><p>文件：<code>crates/goose-server/src/routes/config_management.rs</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// crates/goose-server/src/routes/config_management.rs</span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">async</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">get_provider_models</span>(<span class="hljs-title function_ invoke__">Path</span>(name): Path&lt;<span class="hljs-type">String</span>&gt;) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Result</span>&lt;Json&lt;<span class="hljs-type">Vec</span>&lt;<span class="hljs-type">String</span>&gt;&gt;, ErrorResponse&gt; &#123;<br>    <span class="hljs-keyword">if</span> name == <span class="hljs-string">&quot;azure_openai&quot;</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-title function_ invoke__">Ok</span>(<span class="hljs-title function_ invoke__">Json</span>(<span class="hljs-type">Vec</span>::<span class="hljs-title function_ invoke__">new</span>()));<br>    &#125;<br>    <span class="hljs-comment">// ...其它 provider 走原逻辑...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>2）Provider 元数据：允许 UI 手输“不在列表里的 model”（Azure 语义上就是 deployment name）</p><p>文件：<code>crates/goose/src/providers/azure.rs</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// crates/goose/src/providers/azure.rs</span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">metadata</span>() <span class="hljs-punctuation">-&gt;</span> ProviderMetadata &#123;<br>    ProviderMetadata::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-comment">/* ... */</span>)<br>        .<span class="hljs-title function_ invoke__">with_unlisted_models</span>()<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="与-PR-7034-实际改动的对比"><a href="#与-PR-7034-实际改动的对比" class="headerlink" title="与 PR #7034 实际改动的对比"></a>与 PR #7034 实际改动的对比</h3><p>下面用三张流程图说明：<strong>修复前为什么 404</strong>、<strong>当时推测的改法</strong>、<strong>官方实际改法</strong>。不涉及任何前端知识，只看“请求往哪儿发、结果是什么”即可。</p><hr><h4 id="①-修复前：为什么配置时会-404？"><a href="#①-修复前：为什么配置时会-404？" class="headerlink" title="① 修复前：为什么配置时会 404？"></a>① 修复前：为什么配置时会 404？</h4><p>当时代码把「deployment 名」塞进了<strong>所有请求的共用地址</strong>里，导致「列模型」和「发对话」都用了同一个错误的基础路径：</p><pre><code class=" mermaid">flowchart LR    subgraph 旧代码的共用地址        A[&quot;host = endpoint/openai/deployments/gpt-4.1&quot;]    end    subgraph 列模型时        B[&quot;GET host + &#x27;models&#x27;&quot;]        C[&quot;即 GET .../deployments/gpt-4.1/models&quot;]        D[&quot;Azure 不支持 → 404&quot;]        B --&gt; C --&gt; D    end    subgraph 发对话时        E[&quot;POST host + &#x27;chat/completions&#x27;&quot;]        F[&quot;即 POST .../deployments/gpt-4.1/chat/completions&quot;]        G[&quot;Azure 支持 → 200&quot;]        E --&gt; F --&gt; G    end    A --&gt; B    A --&gt; E</code></pre><p><strong>一句话</strong>：列模型本不该带 <code>deployments/xxx</code>，但旧代码把 host 设成了带 deployment 的地址，所以「列模型」请求发错地方，404；配置页就卡死。</p><hr><h4 id="②-当时推测的改法（应用层兜底）"><a href="#②-当时推测的改法（应用层兜底）" class="headerlink" title="② 当时推测的改法（应用层兜底）"></a>② 当时推测的改法（应用层兜底）</h4><p>不动 URL 构造，在「列模型」这一步直接不请求 Azure，返回空列表，让用户在界面里自己填 deployment 名；发对话时仍然用原来的路径（带 deployment）：</p><pre><code class=" mermaid">flowchart LR    subgraph 列模型        A1[&quot;Desktop 要列模型&quot;]        B1[&quot;服务端发现是 azure_openai&quot;]        C1[&quot;直接返回空列表 []&quot;]        D1[&quot;不请求 Azure → 不会 404&quot;]        A1 --&gt; B1 --&gt; C1 --&gt; D1    end    subgraph 填配置        E1[&quot;用户在界面手填 deployment 名&quot;]    end    subgraph 发对话        F1[&quot;POST .../deployments/xxx/chat/completions&quot;]        G1[&quot;和以前一样 → 200&quot;]        F1 --&gt; G1    end    D1 --&gt; E1    E1 --&gt; F1</code></pre><p><strong>一句话</strong>：不修 URL，而是「列模型」时对 Azure 直接不请求、返回空，让用户手填模型名，从而绕过 404。</p><hr><h4 id="③-官方-PR-7034-的改法（修对-URL）"><a href="#③-官方-PR-7034-的改法（修对-URL）" class="headerlink" title="③ 官方 PR #7034 的改法（修对 URL）"></a>③ 官方 PR #7034 的改法（修对 URL）</h4><p>把「共用地址」和「仅对话用的前缀」拆开：列模型用「不带 deployment」的地址，发对话时才在路径前加上 <code>deployments/xxx/</code>：</p><pre><code class=" mermaid">flowchart LR    subgraph 新代码的地址        H[&quot;host = endpoint/openai&lt;br/&gt;（不再带 deployment）&quot;]        I[&quot;completions_prefix = &#x27;deployments/gpt-4.1/&#x27;&lt;br/&gt;（只用于发对话）&quot;]    end    subgraph 列模型        J[&quot;GET host + &#x27;models&#x27;&quot;]        K[&quot;即 GET .../openai/models&quot;]        L[&quot;不带 deployment → Azure 可接受 → 200&quot;]        J --&gt; K --&gt; L    end    subgraph 发对话        M[&quot;POST host + completions_prefix + &#x27;chat/completions&#x27;&quot;]        N[&quot;即 POST .../openai/deployments/gpt-4.1/chat/completions&quot;]        O[&quot;和以前一样 → 200&quot;]        M --&gt; N --&gt; O    end    H --&gt; J    H --&gt; I    I --&gt; M</code></pre><p><strong>一句话</strong>：列模型用 <code>.../openai/models</code>，发对话用 <code>.../openai/deployments/xxx/chat/completions</code>，各用各的路径，404 消失。</p><hr><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><table><thead><tr><th>维度</th><th>当时推测</th><th>PR #7034 实际改动</th></tr></thead><tbody><tr><td><strong>根因</strong></td><td>列模型时请求了 Azure 不支持的路径 → 404</td><td>一致：deployment 路径被错误地加到了「列模型」的请求上</td></tr><tr><td><strong>实现</strong></td><td>在 <code>config_management.rs</code> 里对 <code>azure_openai</code> 直接返回 <code>[]</code>，不再请求 Azure；provider 加 <code>with_unlisted_models()</code></td><td>不改 config 层，改 <strong>URL 构造</strong>：<code>host</code> 只保留 <code>&#123;endpoint&#125;/openai</code>，<strong>仅</strong>在发 <code>chat/completions</code> 时加上前缀 <code>deployments/&#123;name&#125;/</code>（见 <code>openai_compatible.rs</code> 新增的 <code>completions_prefix</code>）</td></tr><tr><td><strong>结果</strong></td><td>列模型不再打 Azure，404 消失</td><td>列模型请求变为 <code>GET &#123;endpoint&#125;/openai/models</code>（与 <a href="https://github.com/openai/openai-python/blob/main/src/openai/lib/azure.py">openai-python SDK</a> 行为一致），不再带 deployment 路径，404 消失</td></tr></tbody></table><p>两种做法都能打破配置死循环；官方做法是<strong>把 URL 写对</strong>，推测做法是<strong>在应用层不请求、让用户手填</strong>。文中前面的技术细节看不懂也没关系，只要看懂上面三张图：<strong>① 以前错在哪儿 → ② 我们想的办法 → ③ 官方修的办法</strong>，就够用了。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Goose</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Agent</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在 AI Agent 时代学着做一个领导</title>
    <link href="/2025/11/08/career/@2025_be_leader_in_ai_era/"/>
    <url>/2025/11/08/career/@2025_be_leader_in_ai_era/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文先用 Cursor Plan mode Sonnet 4.5 生成 plan，再由 grok-code-fast-1 生成具体文章；（首次AI writing）<br>发现几乎没有人味且幻觉严重距想表达的意思相去甚远，想到连完备的，没有歧义的代码都能乱理解乱改，<br>更别说本来就“约定俗成”的自然语言了，因此最后由人类（本人）就着框架几乎重写了一遍。<br>但不得不说，正如 Coding with AI Agent 一样，对着现成的文章改完全避免了之前写文章出现的<br>大量脑子想了一大堆提笔就卡壳，写着突然忘记上下文等垃圾时间，极大程度一直维持心流状态！<br>毕竟搞建设是有门坎的，但是挑错那可是人民群众与生俱来的看家本事。</p></blockquote><p>由于本人现在都是用英语进行 prompt chating，发现 AI 基本能理解我的英语，且会先总结 my prompt 的一个 smoothly 版本，已经得到了足够的锻炼，因此博客里面就没有必要生拽了。</p><h1 id="新的职责"><a href="#新的职责" class="headerlink" title="新的职责"></a>新的职责</h1><p>这一段我尝试让 AI 帮我写，结果充分体现了什么叫做自然语言的博大精深，这种主观的表达还是只能自己来，所以想到哪里写到哪里，都纯手写的，上面引言中提到的垃圾时间体现得淋漓尽致。</p><h2 id="重回技术"><a href="#重回技术" class="headerlink" title="重回技术"></a>重回技术</h2><p>上一篇博文就用了这个标题，挣扎了这么久，终于回去安心搞技术了，还真能顺便学团队建设。</p><p>正好基本上在去年的这个时候，声网Agora 要垮了把我裁掉，其实在那里的一年也没做到什么有意思的项目。</p><p>最开始说的纯自研前后端统一的 SDK编译发版平台 也随着领导更换回到了维护一堆历史底蕴深厚积重难返的 Jenkins。</p><p>后来加入百度，title 还是 Manager，但实际上干的事情既没技术又不管理。 不到半年火速跑路，现加入了一家小公司担任技术其中一个领导，经过个把月的磨合，现在感觉到身上的责任和挑战了。</p><h2 id="新的挑战"><a href="#新的挑战" class="headerlink" title="新的挑战"></a>新的挑战</h2><p>之前负责带一个实习生的时候，正好又是在项目最忙的时候，疏于团队建设，结果人家直接只复制粘贴 output 到 AI chat，从来不看代码，commit 也不写就提交上去。</p><p>唯一能看的代码还是我手把手教的，一说还一肚子不服气，在多次被团队成员看到摸鱼甚至是转着圈龇牙咧嘴的玩手机的时候，还理直气壮的和 HR 说自己能力没问题，是在等 AI 生成代码。</p><p>领导第一次问我的时候还力保了，等领导第三次过问我突然惊恐地发现这样下去被开的就应该是我了，于是就发生了上述的 HR 客气劝退，结果还委屈地赖着不走的一幕。</p><p>这倒是提醒我了，我现在这个岗位对我的定位不再只是写代码完成自己的功能模块，之后还会有越来越多团队建设的挑战，我现在就要开始调整心态。</p><p>现在这个时代，既要领导人，又要领导 AI，还不能忘基本功。</p><h1 id="AI-Agent-协作：就像打游戏开自动刷怪"><a href="#AI-Agent-协作：就像打游戏开自动刷怪" class="headerlink" title="AI Agent 协作：就像打游戏开自动刷怪"></a>AI Agent 协作：就像打游戏开自动刷怪</h1><h2 id="一、本次任务背景"><a href="#一、本次任务背景" class="headerlink" title="一、本次任务背景"></a>一、本次任务背景</h2><p>这次面临的任务是一个 RPA 自动化项目，基于 DrissionPage 的浏览器自动化框架。项目原本在宿主机运行，需要迁移到 Docker 容器中实现更便捷的部署和管理。</p><p>核心需求是：</p><ol><li><p>用 Docker 实现 GUI 的浏览器自动化；</p></li><li><p>浏览器登录状态必须在容器重启后保持。这是业务的关键要求，不能每次重启都重新登录。</p></li></ol><p>这个任务听起来不复杂，但实际执行中遇到了一系列技术挑战。</p><h2 id="二、传统方式-vs-AI-Agent-方式"><a href="#二、传统方式-vs-AI-Agent-方式" class="headerlink" title="二、传统方式 vs AI Agent 方式"></a>二、传统方式 vs AI Agent 方式</h2><h3 id="2-1-如果没有-AI，我需要做什么"><a href="#2-1-如果没有-AI，我需要做什么" class="headerlink" title="2.1 如果没有 AI，我需要做什么"></a>2.1 如果没有 AI，我需要做什么</h3><p>如果用传统方式解决这个问题，我大概需要：</p><ol><li><strong>搜索 Docker 中运行 GUI 应用的方案</strong> - 研究 headless 浏览器、Xvfb、VNC 等多种方案</li><li><strong>深入研究 Chrome 持久化机制</strong> - 学习 Chrome 的用户数据目录结构和锁机制</li><li><strong>阅读 DrissionPage 官方文档</strong> - 了解框架对容器化部署的支持程度</li><li><strong>尝试各种配置组合</strong> - 在 Docker、Chrome、DrissionPage 之间寻找兼容方案</li><li><strong>调试部署和运行问题</strong> - 解决权限、路径、网络等一系列容器化问题</li></ol><p>这个过程可能需要 5-7 天时间，不断在网上搜索、试错、调整，劳神费心还很可能查到了正确的实践但是没走通。</p><h3 id="2-2-容易陷入的困境"><a href="#2-2-容易陷入的困境" class="headerlink" title="2.2 容易陷入的困境"></a>2.2 容易陷入的困境</h3><p><strong>技术选型迷失</strong>：Docker 中运行 GUI 应用有太多方案 - headless、Xvfb、VNC、noVNC，每种都有优缺点，不知道选哪个。</p><p><strong>调试黑洞</strong>：错误信息往往不明确，一个”连接失败”可能背后有十种原因，需要层层排查。</p><p><strong>时间浪费</strong>：每个方案都要深入研究和尝试才能知道是否可行，很多时候走了弯路。</p><h2 id="三、真实案例：Chrome-持久化问题的解决过程"><a href="#三、真实案例：Chrome-持久化问题的解决过程" class="headerlink" title="三、真实案例：Chrome 持久化问题的解决过程"></a>三、真实案例：Chrome 持久化问题的解决过程</h2><blockquote><p>这里 AI 帮我写的时候漏掉了 Docker 中运行 GUI 应用部分，总之就是 Agent 先提出了一些方案，然后 Agent 就一直自动跑命令行各种尝试，有报错就各种自己 Debug，最后给了我一个方案。</p></blockquote><blockquote><p>最开始那个方案跑出来有问题，然后我让他参考我 Host 机器的 GUI 相关的配置，它就自己生成了 detect 脚本，然后也是自动化的各种改，真的太强了，完全淘汰了很多人引以为豪也是唯一拿得出手的堆工时。</p></blockquote><h3 id="3-1-问题初现"><a href="#3-1-问题初现" class="headerlink" title="3.1 问题初现"></a>3.1 问题初现</h3><p>项目迁移到 Docker 后，第一天就遇到了问题。</p><p><strong>第一次报错</strong>：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs lasso">浏览器连接失败。<br>地址: <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">9310</span><br>提示:<br><span class="hljs-number">1</span>、用户文件夹没有和已打开的浏览器冲突 (尤其是这句，“没有和”<span class="hljs-params">...</span>“冲突”，翻译翻译，把我当日本人整呢？当然其实 root <span class="hljs-keyword">case</span> 就是这个)<br><span class="hljs-number">2</span>、如为无界面系统，请添加<span class="hljs-string">&#x27;--headless=new&#x27;</span>启动参数<br><span class="hljs-number">3</span>、如果是Linux系统，尝试添加<span class="hljs-string">&#x27;--no-sandbox&#x27;</span>启动参数<br></code></pre></td></tr></table></figure><p>这个错误信息很模糊，不知道是 Docker 配置问题、Chrome 配置问题，还是 DrissionPage 的问题。让我很困惑，不知道该从哪里下手。</p><h3 id="3-2-AI-Agent-的诊断过程"><a href="#3-2-AI-Agent-的诊断过程" class="headerlink" title="3.2 AI Agent 的诊断过程"></a>3.2 AI Agent 的诊断过程</h3><h4 id="步骤-1：AI-建议检查挂载卷"><a href="#步骤-1：AI-建议检查挂载卷" class="headerlink" title="步骤 1：AI 建议检查挂载卷"></a>步骤 1：AI 建议检查挂载卷</h4><p>AI Agent 首先帮我检查了 Docker 挂载配置，确认数据目录正确挂载。</p><h4 id="步骤-：AI-和我做了很多的尝试"><a href="#步骤-：AI-和我做了很多的尝试" class="headerlink" title="步骤 *：AI 和我做了很多的尝试"></a>步骤 *：AI 和我做了很多的尝试</h4><p>先是我不断的要求 Plan mode Sonnet 4.5 （费用高） 列出可能的问题，然后让 grok-code-fast-1 （费用低）实践尝试。</p><p>然后查找用到的技术栈的官方文档请 AI 先读一遍，猜测可能的问题。</p><p>我们起码一共试验了五六种可能的大方向，比如说是否某些配置文件挂载有问题，是否各种权限有问题，这个过程中深刻体会到 AI 对上下文动辄就遗忘的赛博老年痴呆。</p><p>说真的，这两个事情让我去做基本上都是垃圾时间。</p><h4 id="步骤-2：AI-建议手动测试-Chrome"><a href="#步骤-2：AI-建议手动测试-Chrome" class="headerlink" title="步骤 2：AI 建议手动测试 Chrome"></a>步骤 2：AI 建议手动测试 Chrome</h4><p>AI 让我在容器中直接运行 Chrome 命令来获取真实错误信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">/usr/bin/google-chrome --remote-debugging-port=9310 \<br>    --user-data-dir=/workspace/browser-data/chrome_data_acct_ \<br>    --no-sandbox --disable-gpu<br></code></pre></td></tr></table></figure><h4 id="步骤-3：发现真实错误"><a href="#步骤-3：发现真实错误" class="headerlink" title="步骤 3：发现真实错误"></a>步骤 3：发现真实错误</h4><p>这次我们看到了真正的错误信息：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-selector-attr">[ERROR]</span> 其他计算机 (e7977e9b8d52) 的另一个 Google Chrome 进程 (<span class="hljs-number">78</span>)<br>        好像正在使用此个人资料。Chrome 已锁定此个人资料以防止其受损。<br></code></pre></td></tr></table></figure><h4 id="步骤-4：AI-分析根本原因"><a href="#步骤-4：AI-分析根本原因" class="headerlink" title="步骤 4：AI 分析根本原因"></a>步骤 4：AI 分析根本原因</h4><p>AI 立即分析出了问题的本质： （即使定位到这里后面都还走了一些弯路）</p><ul><li><code>e7977e9b8d52</code> 是旧容器的 hostname（Docker 自动生成的容器 ID）</li><li><code>78</code> 是旧容器中 Chrome 的进程 ID</li><li>SingletonLock 是符号链接，指向旧容器的进程</li><li>Docker 重启后 hostname 变了，但锁文件还在</li></ul><h4 id="步骤-5：尝试-headless-模式（失败）"><a href="#步骤-5：尝试-headless-模式（失败）" class="headerlink" title="步骤 5：尝试 headless 模式（失败）"></a>步骤 5：尝试 headless 模式（失败）</h4><p>AI 建议添加 <code>--headless=new</code>，但导致 WebSocket 连接失败。我告诉 AI DrissionPage 可能不支持这种模式。（是的，我在无数个 prompt 中明确的说了不要 headless，但是不管是哪个模型都会在试验过其他问题不行的时候，就擅自试一下，开始我很气，后来我想到确实也有可能出现人类一开始判断错误，如果 AI 不去尝试 “我一开始就不行” 的方向，说不定就卡死了）</p><h4 id="步骤-6：实现锁文件清理（第一版失败）（这就是我上文说的，定位到-root-case-之后的弯路之一，一开始他还非不承认有问题）"><a href="#步骤-6：实现锁文件清理（第一版失败）（这就是我上文说的，定位到-root-case-之后的弯路之一，一开始他还非不承认有问题）" class="headerlink" title="步骤 6：实现锁文件清理（第一版失败）（这就是我上文说的，定位到 root case 之后的弯路之一，一开始他还非不承认有问题）"></a>步骤 6：实现锁文件清理（第一版失败）（这就是我上文说的，定位到 root case 之后的弯路之一，一开始他还非不承认有问题）</h4><p>AI 实现了第一版清理代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一版代码（有 bug）</span><br><span class="hljs-keyword">if</span> lock_file.exists():<br>    lock_file.unlink()<br></code></pre></td></tr></table></figure><p>但这个代码有 bug：<code>exists()</code> 检查符号链接的目标，目标不存在返回 False，所以清理代码永远不会执行。</p><h4 id="步骤-7：AI-发现-Python-API-的陷阱"><a href="#步骤-7：AI-发现-Python-API-的陷阱" class="headerlink" title="步骤 7：AI 发现 Python API 的陷阱"></a>步骤 7：AI 发现 Python API 的陷阱</h4><p>AI 通过测试发现：</p><ul><li><code>Path.exists()</code> 检查的是符号链接的目标是否存在</li><li>目标不存在时返回 False，导致清理代码不执行</li><li>需要用 <code>is_symlink()</code> 检查符号链接本身</li></ul><h4 id="步骤-8：正确的实现"><a href="#步骤-8：正确的实现" class="headerlink" title="步骤 8：正确的实现"></a>步骤 8：正确的实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_clean_stale_locks</span>(<span class="hljs-params">self, user_data_dir: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    lock_file = Path(user_data_dir) / <span class="hljs-string">&quot;SingletonLock&quot;</span><br><br>    <span class="hljs-comment"># 关键：检查符号链接本身</span><br>    <span class="hljs-keyword">if</span> lock_file.exists() <span class="hljs-keyword">or</span> lock_file.is_symlink():<br>        lock_file.unlink(missing_ok=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.logger.info(<span class="hljs-string">f&quot;Cleaned stale lock file: <span class="hljs-subst">&#123;lock_file&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="步骤-9：超时时间调整（这里我说了不需要，超时是有问题连不上，他还是硬要加上）"><a href="#步骤-9：超时时间调整（这里我说了不需要，超时是有问题连不上，他还是硬要加上）" class="headerlink" title="步骤 9：超时时间调整（这里我说了不需要，超时是有问题连不上，他还是硬要加上）"></a>步骤 9：超时时间调整（这里我说了不需要，超时是有问题连不上，他还是硬要加上）</h4><p>AI 发现 Chrome 在容器中启动变慢，建议增加超时时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">DrissionSettings.set_browser_connect_timeout(<span class="hljs-number">60</span>)<br></code></pre></td></tr></table></figure><h4 id="步骤-10：验证成功"><a href="#步骤-10：验证成功" class="headerlink" title="步骤 10：验证成功"></a>步骤 10：验证成功</h4><p>最终验证成功：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">19</span>:<span class="hljs-number">44</span>:<span class="hljs-number">53</span> | INFO  | Cleaned stale lock file: browser-data/chrome_data_acct_/SingletonLock<br><span class="hljs-attribute">19</span>:<span class="hljs-number">44</span>:<span class="hljs-number">54</span> | INFO  | ✓ Successfully created Chrome browser for acct_ <span class="hljs-literal">on</span> port <span class="hljs-number">9287</span><br></code></pre></td></tr></table></figure><h3 id="3-3-技术细节：SingletonLock-机制"><a href="#3-3-技术细节：SingletonLock-机制" class="headerlink" title="3.3 技术细节：SingletonLock 机制"></a>3.3 技术细节：SingletonLock 机制</h3><h4 id="问题本质"><a href="#问题本质" class="headerlink" title="问题本质"></a>问题本质</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 锁文件是符号链接</span><br>$ <span class="hljs-built_in">ls</span> -la SingletonLock<br>lrwxrwxrwx SingletonLock -&gt; e7977e9b8d52-78<br>                            └─────┬────┘ └┬┘<br>                             旧容器ID    旧进程ID<br></code></pre></td></tr></table></figure><h4 id="Docker-重启流程"><a href="#Docker-重启流程" class="headerlink" title="Docker 重启流程"></a>Docker 重启流程</h4><blockquote><p>AI 太厉害了，这个图你让我画我都要磨蹭半天</p></blockquote><pre><code class=" mermaid">sequenceDiagram    participant Docker as Docker容器    participant Chrome as Chrome进程    participant Lock as SingletonLock    participant Disk as 挂载卷    Note over Docker: 旧容器 (e7977e9b8d52)    Chrome-&gt;&gt;Lock: 创建 SingletonLock -&gt; e7977e9b8d52-78    Lock-&gt;&gt;Disk: 写入挂载卷    Note over Docker: 容器重启    Docker-&gt;&gt;Chrome: 杀死进程    Note over Lock: 锁文件保留在磁盘    Note over Docker: 新容器 (d12eb5af59ba)    Chrome-&gt;&gt;Lock: 检测到 SingletonLock -&gt; e7977e9b8d52-78    Chrome-&gt;&gt;Chrome: hostname 不匹配！    Chrome--xChrome: 拒绝启动</code></pre><h2 id="四、AI-Agent-的震撼之处"><a href="#四、AI-Agent-的震撼之处" class="headerlink" title="四、AI Agent 的震撼之处"></a>四、AI Agent 的震撼之处</h2><h3 id="4-1-真实完成的工作量统计"><a href="#4-1-真实完成的工作量统计" class="headerlink" title="4.1 真实完成的工作量统计"></a>4.1 真实完成的工作量统计</h3><p><strong>AI Agent 自动执行的任务</strong>（来自聊天记录）：</p><ol><li>检查 Docker 配置和挂载卷（5+ 次命令）</li><li>分析文件权限和目录结构（8+ 次命令）</li><li>手动测试 Chrome 启动（3+ 次尝试）</li><li>编写和执行调试脚本（10+ 个脚本）</li><li>分析 DrissionPage 源码（3 个文件）</li><li>实现和修复代码（5 次迭代）</li><li>编写测试用例（3 个测试文件）</li><li>更新文档（README 中英文）</li><li>生成 git commit（2 次提交）</li></ol><p><strong>时间对比</strong></p><ul><li>人工预计：5-7 天</li><li>AI Agent 实际：约 4 小时</li><li>效率提升：10-20 倍</li></ul><p><strong>心情对比</strong></p><ul><li>像打游戏开了自动寻路一样</li></ul><h3 id="4-2-AI-Agent-的核心价值"><a href="#4-2-AI-Agent-的核心价值" class="headerlink" title="4.2 AI Agent 的核心价值"></a>4.2 AI Agent 的核心价值</h3><h4 id="1-快速信息整合"><a href="#1-快速信息整合" class="headerlink" title="1. 快速信息整合"></a>1. 快速信息整合</h4><p>自动关联 Docker、Chrome、DrissionPage 知识，无需人类手动搜索和阅读大量文档，直接给出最相关的解决方向。</p><blockquote><p>说真的这里面即使我熟悉的技术栈我真看的时候也得小心翼翼，root case 对应的文档部分一定会在某个不经意的地方被漏掉的。</p></blockquote><h4 id="2-自动化执行与验证"><a href="#2-自动化执行与验证" class="headerlink" title="2. 自动化执行与验证"></a>2. 自动化执行与验证</h4><p>立即执行命令并分析结果，发现问题立即调整策略，自动生成测试脚本验证。</p><blockquote><p>说真的你要我去写，测试代码我都要构造好久，我还没写完 Agent 都跑完了，我再写一百年代码我也没这个能力。</p></blockquote><h4 id="3-系统化问题追踪"><a href="#3-系统化问题追踪" class="headerlink" title="3. 系统化问题追踪"></a>3. 系统化问题追踪</h4><p>从表面错误（连接失败）→ 真实错误（SingletonLock）→ 根本原因（符号链接 + Docker hostname）→ 完整解决方案（清理 + 超时调整）</p><h4 id="4-代码质量保证"><a href="#4-代码质量保证" class="headerlink" title="4. 代码质量保证"></a>4. 代码质量保证</h4><p>自动处理边界条件（<code>missing_ok=True</code>）、完善的错误处理、详细的代码注释、自动生成文档。</p><h3 id="4-3-如果是我自己做"><a href="#4-3-如果是我自己做" class="headerlink" title="4.3 如果是我自己做"></a>4.3 如果是我自己做</h3><p><strong>可能的困境</strong>：</p><ol><li>在 GUI in Docker 具体方案如 Xvfb 之间纠结很久，试验成本太高</li><li>看到”连接失败”不知道从何查起</li><li>即使发现 SingletonLock，也可能不知道是符号链接问题</li><li>可能写出有 bug 的代码，然后困惑为什么不工作</li><li>需要深入研究 Python pathlib 文档才能发现 <code>exists()</code> 的陷阱</li></ol><p><strong>预计耗时</strong>：<br>别预计了上不封顶，预计到被开为止</p><h2 id="五、AI-Agent-的局限性（真实体验）"><a href="#五、AI-Agent-的局限性（真实体验）" class="headerlink" title="五、AI Agent 的局限性（真实体验）"></a>五、AI Agent 的局限性（真实体验）</h2><h3 id="5-1-需要人类提供方向"><a href="#5-1-需要人类提供方向" class="headerlink" title="5.1 需要人类提供方向"></a>5.1 需要人类提供方向</h3><p><strong>真实案例</strong></p><ul><li>AI 最初建议用 headless 模式，但我知道 DrissionPage 可能不支持（你看又瞎写，我强调了很多次是业务上不能，有些目标网站不能用 headless 这个必须我们后面手动试出来，他就是总有自己的理解）</li><li>AI 需要我提供 DrissionPage 官方文档链接（不然我看它一直在自己写一堆方法去调 .venv&#x2F;lib&#x2F;python3.12&#x2F;site-packages&#x2F;DrissionPage&#x2F;_pages&#x2F;chromium_page.py 人家库里面的 API 验证，我让他打开 Connected to External Browser 官方文档两下就解决了）</li><li>AI 需要我确认业务场景（必须保持登录状态）</li></ul><h3 id="5-2-需要人类验证结果"><a href="#5-2-需要人类验证结果" class="headerlink" title="5.2 需要人类验证结果"></a>5.2 需要人类验证结果</h3><p><strong>真实案例</strong></p><ul><li>AI 生成的第一版清理代码有 bug，我需要在 Docker 容器中实际测试</li><li>我需要确认登录状态是否真的保留了</li></ul><h3 id="5-3-LLM-的幻觉问题"><a href="#5-3-LLM-的幻觉问题" class="headerlink" title="5.3 LLM 的幻觉问题"></a>5.3 LLM 的幻觉问题</h3><p><strong>真实案例</strong></p><ul><li>AI 有时会建议不存在的 DrissionPage API，需要我查阅官方文档确认</li><li>更别说经典的自己编 API 然后一运行就报错了</li><li>关键决策需要我最终拍板</li></ul><blockquote><p>后面都是一堆漂亮的车轱辘话，我全删了</p></blockquote><hr><h2 id="附录：关键代码实现"><a href="#附录：关键代码实现" class="headerlink" title="附录：关键代码实现"></a>附录：关键代码实现</h2><h3 id="SingletonLock-清理实现"><a href="#SingletonLock-清理实现" class="headerlink" title="SingletonLock 清理实现"></a>SingletonLock 清理实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_clean_stale_locks</span>(<span class="hljs-params">self, user_data_dir: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;清理过时的Chrome锁文件（Docker重启场景）&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> user_data_dir:<br>        <span class="hljs-keyword">return</span><br><br>    lock_file = Path(user_data_dir) / <span class="hljs-string">&quot;SingletonLock&quot;</span><br><br>    <span class="hljs-comment"># 关键：检查符号链接本身（不检查目标是否存在）</span><br>    <span class="hljs-keyword">if</span> lock_file.exists() <span class="hljs-keyword">or</span> lock_file.is_symlink():<br>        <span class="hljs-keyword">try</span>:<br>            lock_file.unlink(missing_ok=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.logger.info(<span class="hljs-string">f&quot;Cleaned stale lock file: <span class="hljs-subst">&#123;lock_file&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-variable language_">self</span>.logger.warning(<span class="hljs-string">f&quot;Failed to clean lock file <span class="hljs-subst">&#123;lock_file&#125;</span>: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="调用时机"><a href="#调用时机" class="headerlink" title="调用时机"></a>调用时机</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_session</span>(<span class="hljs-params">self, session_id: <span class="hljs-built_in">str</span>, persistent: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                   user_data_dir: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span></span>) -&gt; Chromium:<br>    <span class="hljs-comment"># 清理过时锁文件（Docker 重启场景）</span><br>    <span class="hljs-keyword">if</span> persistent <span class="hljs-keyword">and</span> user_data_dir:<br>        <span class="hljs-variable language_">self</span>._clean_stale_locks(<span class="hljs-built_in">str</span>(user_data_dir))<br><br>    <span class="hljs-comment"># 现在可以安全启动 Chrome</span><br>    browser = Chromium(addr_or_opts=options)<br>    <span class="hljs-keyword">return</span> browser<br></code></pre></td></tr></table></figure><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p>别整一堆静态链接了，说不定点进去发现都过期了。让 AI 现场生成，已经又准又精炼了，感觉是从以前的游戏 CG 进化到了实时渲染的美。</p></blockquote><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Review</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2025 Fitness Journey Record</title>
    <link href="/2025/09/01/career/@2025_fitness_record/"/>
    <url>/2025/09/01/career/@2025_fitness_record/</url>
    
    <content type="html"><![CDATA[<p>之前维护了一个实时记录贴，想到哪写到哪，所以格式杂乱，现重整理总结贴。</p><h1 id="近况更新-（2026年3月）"><a href="#近况更新-（2026年3月）" class="headerlink" title="近况更新 （2026年3月）"></a>近况更新 （2026年3月）</h1><p>跨越一年了，进步很大，减了 30+ 斤，体脂也从 33.3% -&gt; 24.4%。</p><p>看样子等到天气热，能系统锻炼时，就可以追求前所未有的目标了。</p><span id="more"></span><p>最胖 218.6斤 体脂 33.3% 72.8斤（脂肪）<br>最瘦 179.4斤 体脂 23.3% 41.8斤（脂肪）</p><h1 id="Weight"><a href="#Weight" class="headerlink" title="Weight"></a>Weight</h1><p>印象中最胖是 230斤，但是体脂秤记录的数据是 218斤，不知道是超过秤的上限，还是当时羞于记录。</p><p>2025年开年便是 205斤 了，已经减了 10斤，到达在深圳时一直挣扎的体重。</p><h2 id="总的进度"><a href="#总的进度" class="headerlink" title="总的进度"></a>总的进度</h2><table><thead><tr><th>时间</th><th>体重</th><th>体脂率</th><th>阶段说明</th></tr></thead><tbody><tr><td>2024.10.04</td><td>218.6斤</td><td>33.3%</td><td>即将再次失业，还不能遇见到会发生什么。</td></tr><tr><td>2024.12.03</td><td>210斤</td><td>31.7%</td><td>【减】儿子出生时开始下定决心，开始一个多月就 -8斤。</td></tr><tr><td>2025.01.17</td><td>205斤</td><td>31.0%</td><td>【减】 声网垮了，在家想起封控的时候也没饿死，遂开始极端克制饮食。</td></tr><tr><td>2025.02.27</td><td>199斤</td><td>29.3%</td><td>【减】失业三个月极端少吃成果，但回过头来看知只是昙花一现罢了。</td></tr><tr><td>2025.05.25</td><td>200斤</td><td>29.1%</td><td>【反弹】刚到百度贪图免费餐，同时也在内心放松警惕，中间甚至再次胖回 207斤 ，整顿后再突破 200斤。</td></tr><tr><td>2025.07.13</td><td>193.7斤</td><td>26.9%</td><td>【减】后来发现秤会漂移，同时吸取之前的教训稳定下 195斤 一段时间后再记录！</td></tr><tr><td>2025.07.29</td><td>189.8斤</td><td>26.1%</td><td>【减】首次下 190斤 减了 30斤 了，距离脱离“胖子”还有一半。</td></tr><tr><td>2025.09.02</td><td>189.7斤</td><td>26.2%</td><td>【反弹】陷入了一个巨大的瓶颈期，不过想想刚到百度时的回落，好在意识到了，期待之后的记录。</td></tr><tr><td>2026.01.08</td><td>188.7斤</td><td>25.6%</td><td>【减】稳住了，同时第一次 BMI 体脂同时离开“肥胖”，正式进入“偏胖”。</td></tr><tr><td>2026.02.23</td><td>186.9斤</td><td>24.4%</td><td>【减】关注体脂，终于跨过之前最痛苦也用时最多的平台期阶段，更自信地朝着目标前进了。</td></tr></tbody></table><p>本阶段（2026年上半年）的目标，也是大学最瘦的时候： 179.4斤 23.3% 41.8斤（脂肪）</p><h2 id="稳定到-24-–-2026-02-23"><a href="#稳定到-24-–-2026-02-23" class="headerlink" title="稳定到 24% – 2026.02.23"></a>稳定到 24% – 2026.02.23</h2><p>186.9斤 24.4% 45.6斤（脂肪） 134.0斤（肌肉）<br>如果说之前体脂 25% ~ 26% 那段时期，是重复的痛苦迷茫和自我怀疑，那么这次，当我年后第一次发现自己体脂直接来到 24% ，且最近我并没有什么特意进步带来的痛苦体验的时候，肯定是怀疑秤坏了或者像之前每次那样偶然误差空欢喜罢了。</p><div style="display: flex">  <img src="07_77.jpeg" alt="" style="">  <img src="07_79.jpeg" alt="" style="">  <img src="07_82.jpeg" alt="" style="">  <img src="07_84.jpeg" alt="" style="">  <img src="07_88.jpeg" alt="" style=""></div><p>因此又观察了一个星期，这次发现不仅体脂稳定下来，而且脂肪重量还在每天真的有序递减，才终于安心了。</p><p>现在有些时候也会像之前那样下地铁后步行 3公里，但现在已经可以不用护膝走跑，这是之前不敢想象的。</p><h2 id="稳定“偏胖”-–-2026-01-08"><a href="#稳定“偏胖”-–-2026-01-08" class="headerlink" title="稳定“偏胖” – 2026.01.08"></a>稳定“偏胖” – 2026.01.08</h2><p>188.7斤 25.6% 48.2斤（脂肪） 133.0斤（肌肉）<br>有过振荡有过迷茫，体重最少达到过 186斤，综合看下来确实比大学时候都更瘦了，期待下一个目标的实现。</p><h2 id="9月反弹期间更新"><a href="#9月反弹期间更新" class="headerlink" title="9月反弹期间更新"></a>9月反弹期间更新</h2><p>已经进入一个很大的平台期了，从8月再次减到 190斤 后，持续继续节食一个半月体重一直振荡就是不降，期间还饿出过眼冒金星的低血糖。</p><p>同时，在稍微放开吃一点东西的情况下，体重飙升，这才是真实的自己。</p><p>明显意识到需要调整方法了，正好探索一下现在体重的身体应该如何加上锻炼。</p><div class="note note-info">            <p>今年落实了以前只存在想象中的计划： 减肥 30+斤， 看来这次是真的能展开不一样的人生了。</p><p>最大的总结是少吃是饿不死人的，反而胃口会变小。保持热量差是减肥唯一且朴实无华的道理。</p>          </div><h2 id="下-190斤-–-2025-07-29"><a href="#下-190斤-–-2025-07-29" class="headerlink" title="下 190斤  – 2025.07.29"></a>下 190斤  – 2025.07.29</h2><p>189.8斤 26.1%</p><p>减了一半，还剩一半。 到 178斤 （最后 10斤）的时候我会好好休息一下。</p><p>已经回到大学时候体重，之后减的每一斤都是净赚。</p><img src="05_backto_teen.png" alt="weight_returns_to_youth" style="width: 60%;"><p>在小红书上开贴记录了减肥的每个时间节点，下次再发就是下到 178斤 以后了。</p><p>同时解决了之前的一个疑惑： 我能做引体向上到底是因为力量变大了，还是减肥了。<br><img src="/2025/09/01/career/@2025_fitness_record/05_weight_190.png" alt="down to 190 jin"></p><p>考虑到误差，我是在 08.03日 后观察到体重稳定徘徊在 190斤 一段时间，才在此记录是真的又进入另一个阶段。</p><p>不过比起当天几乎快下 26% 的体脂，现在还是挺高的，几乎和上一个阶段没有变化。</p><p>快了，所有的指标都在趋向正常，等我下一个阶段之后，就从最开始只有两个指标正常到只有两个指标不正常了，加油，行百里者半九十。</p><h2 id="195-斤-–-2025-07-13"><a href="#195-斤-–-2025-07-13" class="headerlink" title="195 斤 – 2025.07.13"></a>195 斤 – 2025.07.13</h2><p>193.7斤 6.9%<br>回过头看，还真的是非常科学的一个月5斤，一周一斤。<br>最近不知道是秤还是称重姿势问题，同一时刻有时能偏差一斤。<br>实际上前几天就飘下过 195斤，但为了保险，今天才进行记录。</p><p>现在对甜食或者甜味有本能的抵制了，有时想到小时候吃完饭还用炒菜的红油泡饭吃，都忘了从什么时候逐渐开始改变观念的。</p><h2 id="200-斤-–-2025-05-25"><a href="#200-斤-–-2025-05-25" class="headerlink" title="200 斤 – 2025.05.25"></a>200 斤 – 2025.05.25</h2><p>2025.05.25 很巧啊，正好又是过了一个月，前几天心态还随着体重的尾巴反复起伏，在周五没胃口的限制饮食下，竟然一路高歌猛进，直接突破。</p><div style="display: flex; gap: 40px;">  <img src="04_weight_200.png" alt="终于下200了" style="width: 77%;">  <img src="04_is_you.png" alt="这是你吗？" style="width: 77%;"></div><h2 id="205-斤-–-2025-01-17"><a href="#205-斤-–-2025-01-17" class="headerlink" title="205 斤 – 2025.01.17"></a>205 斤 – 2025.01.17</h2><p>2025.04.24 近 30 天差不多是这个平均体重，这也是我开始适应张江工作后刚开始新的运动方式的起始体重。</p><p>同时，我在深圳一边锻炼一边狂吃也是这个体重，这4年里体重两度掉下 200 斤。</p><hr><h1 id="Running"><a href="#Running" class="headerlink" title="Running"></a>Running</h1><blockquote><p>工作日中饭，晚饭时间各跑一小时，争取早上和晚上下班也能各跑半小时。  要是能按照这个节奏跑下来，不出半年我就强的可怕。</p></blockquote><p>以上是当时在张江的展望，不过并没有真的抽出那么多时间来跑步，反而是临近跑路的那一个月真的间歇执行了，从手环上看得出总共一万五千步，效果还是非常明显的，详见<a href="#6km-%E8%86%9D%E7%9B%96%E6%97%A0%E6%84%9F-%E2%80%93-2025-08-28">→ 6km 膝盖无感</a></p><h2 id="6km-膝盖无感-–-2025-08-28"><a href="#6km-膝盖无感-–-2025-08-28" class="headerlink" title="6km 膝盖无感 – 2025.08.28"></a>6km 膝盖无感 – 2025.08.28</h2><div style="display: flex; gap: 40px;">  <img src="03_running_6km.png" alt="6km running" style="width: 77%;">  <img src="03_step_statistics.png" alt="step statistics" style="width: 77%;"></div><p>实在是太神奇了，高贵的浦西上班跑步回家的含金量。</p><p>减肥 30斤 后，一口气走跑 6km，不需要任何的辅助设备， 第二天别说左边膝盖痛了，连酸胀都没有。</p><p>日积月累，滴水石穿，看来之前半年在张江的大公园的散步让我已经习惯了间歇一天突破一万五千步的节奏。</p><p>真的之前在谷底的时候难以想象这种状态，接下来要做的就是选个状态好的时候，开始长距离的跑回去了。</p><p>想想我现在可以用上下班这个通勤距离来跑步，要是坚持个半年，进步该有多大！</p><div class="note note-warning">            <p>update: <strong>过几天发现实际上膝盖还是有感</strong> 不管是骑车还是走路的时候都感觉有点胀胀的感觉，但是比起以前两百多斤强有力到甚至刺痛的感觉，现在已经微弱到只能像当时骑车 20公里 到五角场之后的感觉，远远不似真的跑步的感觉强度。</p>          </div><h2 id="10min-–-2025-05-07"><a href="#10min-–-2025-05-07" class="headerlink" title="10min – 2025.05.07"></a>10min – 2025.05.07</h2><p>带护膝，一口气（慢）跑了10分钟，7分钟才开始喘40不适症状。<br>最近并没有完全坚持训练，且本次只是想稍微尝试，结果没想当进步如此巨大。</p><h2 id="5min-–-2025-04-24"><a href="#5min-–-2025-04-24" class="headerlink" title="&lt; 5min – 2025.04.24"></a>&lt; 5min – 2025.04.24</h2><h2 id="没带护膝，跑55到-5-分钟，膝盖就开始痛。"><a href="#没带护膝，跑55到-5-分钟，膝盖就开始痛。" class="headerlink" title=" 没带护膝，跑55到 5 分钟，膝盖就开始痛。"></a> 没带护膝，跑55到 5 分钟，膝盖就开始痛。</h2><h1 id="Hiking‌"><a href="#Hiking‌" class="headerlink" title="Hiking‌"></a>Hiking‌</h1><p>最初写这篇博客的时候，潇洒地写下准备两周一次的徒步，结果就像之前每一次计划一样根本没有展开，好在今年剩下的 1&#x2F;4 里应该能努力维持一下这个节奏。</p><h2 id="9-13-Take-a-walk-in-the-park"><a href="#9-13-Take-a-walk-in-the-park" class="headerlink" title="9.13 Take a walk in the park"></a>9.13 Take a walk in the park</h2><p>真的很神奇，可能快十年没有体验过不到两百斤徒步的体验了。</p><p>想着稳妥起见，参加了多年前经常一起去的搞城市活动的非专业玩耍团的徒步活动，结果直接成了公园景区散步了。</p><img src="01_03.jpeg" alt="take photo" style="width: 77%;"><p>全程没有一点波动，看着别人喘真的是一件很有成就感的事情。</p><img src="01_04.jpeg" alt="walk" style="width: 77%;"><p>膝盖有酸胀，滞胀但是就是没有刺痛的感觉，太幸福了，从来没有享受过这样的待遇。</p><h2 id="4-20-Weakly-fall-behind"><a href="#4-20-Weakly-fall-behind" class="headerlink" title="4.20 Weakly fall behind"></a>4.20 Weakly fall behind</h2><p>从上一次被开中缓过来，才发现自己用年来计算没有出去转过的日子了。</p><p>拖着两百多点斤的身体，走到后面左腿膝盖开始疼痛，完全落在后面，喘着气耽误这领队收尾。</p><div style="display: flex; gap: 40px;">  <img src="01_01.jpg" alt="up" style="width: 90%;">  <img src="01_02.jpeg" alt="top" style="width: 60%;"></div><hr><h1 id="Pull-Up（已完结）"><a href="#Pull-Up（已完结）" class="headerlink" title="Pull-Up（已完结）"></a>Pull-Up（已完结）</h1><p>2025.06.06 对我来说是个<strong>很重要的日子</strong>，本来只是心血来潮的想试一下，结果直接做到了人生中第一个标准引体向上。</p><p>现在已经习惯性的少吃，也不会像以前一样恐惧饥饿。</p><p>晚上出去吃的，但已经很克制不会“加餐”，消灭未完的食物了。回家称到体重也没有上到200.</p><p>前段时间一直晚上都难以入睡，终于从前天开始能正常睡觉。</p><p>三十而立，明白了这么多的道理，经过了这些年的实践后，现在要开始<strong>真正的人生</strong>。</p><iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114636787551157&bvid=BV1NgTMzPEAG&cid=30355948788&p=1&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="width: 100%; height: 500px;"> </iframe><blockquote><p>众所周知 Wide-Grip Pull-Up 宽距正手引体 是最标准的，我现在有以下3条不同力道的弹力带，用于辅助。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2~15磅&quot;</span> <span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;13~35磅&quot;</span> <span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;25~65磅&quot;</span> <span class="hljs-punctuation">&#125;</span> <br></code></pre></td></tr></table></figure><p>目标</p><ul><li><input checked="" disabled="" type="checkbox"> 年中 弹力带2 的辅助下做1个标准引体向上</li><li><input disabled="" type="checkbox"> 年底 弹力带1 的辅助下做1个标准引体向上</li><li><input disabled="" type="checkbox"> 预期 做1个标准引体向上<br><img src="/2025/09/01/career/@2025_fitness_record/02_pullup_technique.png" alt="中距半正手"><br>2025.05.22 无意中发现自己已经能用一种折中的中距半正手做引体向上，期待解锁标准引体向上，这是我从来没有达到过的境地。</li></ul></blockquote><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Record</tag>
      
      <tag>Fitness</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sliding window is not only the index offset</title>
    <link href="/2025/08/09/leetcode/@2025_3.%20Longest%20Substring%20Without%20Repeating%20Characters/"/>
    <url>/2025/08/09/leetcode/@2025_3.%20Longest%20Substring%20Without%20Repeating%20Characters/</url>
    
    <content type="html"><![CDATA[<p>The sliding window MUST operate within a single loop! Every time adjusting only one index per iteration! Never move both simultaneously otherwise it will be O(n^2)!</p><span id="more"></span><p><a href="https://github.com/gou7ma7/leetcode/blob/master/3.%20Longest%20Substring%20Without%20Repeating%20Characters.py">https://github.com/gou7ma7/leetcode/blob/master/3.%20Longest%20Substring%20Without%20Repeating%20Characters.py</a></p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Very funny, I just unexpectlly find out that it is 3rd of Leetcode, but I only remembered that it should be resolved by sliding window.</p><h1 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h1><p>A <strong>sliding window</strong> is not merely defined by two numerical index: the left offset and the right offset.</p><h1 id="Intuitive-version"><a href="#Intuitive-version" class="headerlink" title="Intuitive version"></a>Intuitive version</h1><p>We init left and right index, and between string[left: right] slide is the windows, this is very intuitive.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">intuitive</span>(<span class="hljs-params">s</span>):<br>    len_s = <span class="hljs-built_in">len</span>(s) - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> len_s &lt; <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">if</span> len_s &lt; <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>, s[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> s[<span class="hljs-number">0</span>] == s[<span class="hljs-number">1</span>] <span class="hljs-keyword">else</span> <span class="hljs-number">2</span>, s<br>    left = right = <span class="hljs-number">0</span><br>    len_s = <span class="hljs-built_in">len</span>(s) - <span class="hljs-number">1</span><br>    result_substring = <span class="hljs-string">&#x27;&#x27;</span><br>    max_len = <span class="hljs-number">1</span><br>    record_set = <span class="hljs-built_in">set</span>()<br>    <span class="hljs-keyword">while</span> left &lt; len_s - <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">if</span> s[right] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> record_set:<br>            <span class="hljs-keyword">if</span> max_len &lt;= right + <span class="hljs-number">1</span> - left:<br>                result_substring = s[left: right+<span class="hljs-number">1</span>]<br>                max_len = right + <span class="hljs-number">1</span> - left<br>            <br>            record_set.add(s[right])<br>            <span class="hljs-keyword">if</span> right &lt; len_s:<br>                right += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">else</span>:<br>            record_set.remove(s[left])<br>            left += <span class="hljs-number">1</span><br>        <br>        <br>    <span class="hljs-keyword">return</span> max_len, result_substring<br></code></pre></td></tr></table></figure><p>The coding process is so smoothly, it must be that I was too <strong>NERVOUS</strong> to coding a O(n^3) algorithm.</p><p>What A STUPID man!</p><p>The window slide only in a loop, move right and left should be in a same leveled loop! </p><p>That time I got a outter loop to move right, and another inner loop to move left, and what is more, maintain a s[now_left: now_right+1] to check whether it contains duplicate char each loop.</p><p>With above code, it seems that it should a Medium…</p><p>And with replacing record_set -&gt; record_dict, it IS O(n) now.</p><p>It’s over. All is lost.</p><h1 id="Slide-with-record"><a href="#Slide-with-record" class="headerlink" title="Slide with record"></a>Slide with record</h1><p>In above code, you can see that the set()&#x2F;dict() is always add a element and move the same one, and what is more, there are so many break when right &lt; len and now char not in <code>record_dict</code>, so we could use a dict to record index, and reassign it to means “Oh, now window contains repeated char, we should slide it to get a new window”.</p><p>But the time complex is same as intuitive version, just substract some branch, if nervious, just use initial version!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">slide_with_record</span>(<span class="hljs-params">s</span>):<br>    left = <span class="hljs-number">0</span><br>    max_right = <span class="hljs-number">0</span><br>    max_len = <span class="hljs-number">0</span><br>    record_dict = &#123;&#125;  <span class="hljs-comment"># Did you see that the above set is always remove and add a same char, so can I combine the too action?</span><br>    <span class="hljs-keyword">for</span> right, char <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>        <span class="hljs-keyword">if</span> char <span class="hljs-keyword">in</span> record_dict <span class="hljs-keyword">and</span> record_dict[char] &gt;= left:  <span class="hljs-comment"># now turn get repeat, so the len of windows won&#x27;t increase, only slide left</span><br>            <br>            left = record_dict[char] + <span class="hljs-number">1</span><br>        <br>        <span class="hljs-comment"># slide the repeated char&#x27;s left to now + 1 to count window if next this repeated char appear again. (if appear is not the char, of cause ignore the char&#x27;s left index, it will count itself&#x27;s left index)</span><br>        record_dict[char] = right<br>        <span class="hljs-keyword">if</span> max_len &lt;= right - left + <span class="hljs-number">1</span>:<br>            max_len = right - left + <span class="hljs-number">1</span><br>            max_right = right<br><br>    <span class="hljs-keyword">return</span> max_len, s[max_right - max_len + <span class="hljs-number">1</span>: max_right + <span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Medium</tag>
      
      <tag>Sliding window</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Life is a Game: Ditch the Tech Obsession</title>
    <link href="/2025/08/01/career/@2025_life_is_a_game_ditch_the_tech_obsession/"/>
    <url>/2025/08/01/career/@2025_life_is_a_game_ditch_the_tech_obsession/</url>
    
    <content type="html"><![CDATA[<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114943256956471&bvid=BV1Ge8zztEiK&cid=31392662799&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="width: 100%; height: 500px;"> </iframe>文化工作者一定要有文化<hr><p>这篇文章是针对 2025年 前半年的一个小小总结吧，因此不用生拽英文了。</p><p>也是我站在一个自诩的核心游戏玩家的角度 “技术” 在我职业发展规划的一些反思。</p><p>到百度也快半年了，在这个 M 序列 (Management Sequence) 也呆过了，能从一个更多的视角看待 “技术” 。</p><div class="note note-warning">            <p>update: <strong>办理离职的时候才发现我是 E 序列</strong> - ENTERPRISE&#x2F;GOVERNMENT SOLUTION &amp; SERVICE，政企行业解决方案和服务序列。</p><p>只是因为我的 title 是 manager 结尾，并且去甲方的时候按理会带上外包，所以我就以为我是 M，同时反正只要不是 T 序列都没啥区别。</p>          </div><h1 id="游戏没有带娃硬核"><a href="#游戏没有带娃硬核" class="headerlink" title="游戏没有带娃硬核"></a>游戏没有带娃硬核</h1><h2 id="很难挂念"><a href="#很难挂念" class="headerlink" title="很难挂念"></a>很难挂念</h2><p>我一直认为游戏是对现实世界的一种片面的模拟，同时也是一种高度特性的学习。</p><p>或许是从其他地方得到的正反馈越来越多，现在从游戏中获得的快乐越来越少，同时可能由于见识的增长，很容易就看出当前游戏是对某个高度特性的知识体系（甚至不能叫体系，只能叫技能组合）的学习，因此很快就腻了。</p><h2 id="相识亚楠"><a href="#相识亚楠" class="headerlink" title="相识亚楠"></a>相识亚楠</h2><p>以前一段时间我曾以为我是魂系游戏的受众，后来发现自己只是喜欢玩《血源诅咒》罢了。</p><p>我一直好奇很多年以后我们小孩知道一切的开始是因为他的妈妈借 PS4 给他的爸爸玩《血源诅咒》的时候他会怎么想。</p><p>不过可能那个时候已经实现了真正的元宇宙了，app, 游戏, 现实的界限会模糊不清。</p><p>结婚之前我们一起玩了很多游戏，也时常一起和朋友们鏖战《英雄联盟》，感觉就像回到大学宿舍天天不上课那段时间，只是肯定不会像当时那样又空虚又迷茫。</p><h2 id="对两性关系的思考"><a href="#对两性关系的思考" class="headerlink" title="对两性关系的思考"></a>对两性关系的思考</h2><p>以前在知乎上看到： 情侣（或者其他）之间的亲密关系靠生产维系的要大大好于消费。</p><p>生完小孩之后我们就再也没有在一起打过游戏了。（最后一次是在怀孕期间医院一起玩的 《文明6》）</p><p>虽然我只负责在带娃方面打下手，但是依旧觉得这是一个非常硬核的游戏，我家的娃已经是 Easy mode， 非必要情况不会哭闹，而且反馈给得很足，能让我看到我发出的指令能有回应，绝大多数时候能给我极大的满足。</p><p>但是在处理像落地醒的时候还是非常折磨人的，一遍遍地尝试却不得要领的时候，耐心尽失脑袋发懵，总不自觉会回想起来“中学考试の怜悯” – 划重点啊划重点。</p><h2 id="合作，与游戏对比"><a href="#合作，与游戏对比" class="headerlink" title="合作，与游戏对比"></a>合作，与游戏对比</h2><p>费孝通先生在《乡土中国》中描述的中国特有的“爱情”发生在同性之间，夫妻之间只存在合作。</p><p>我想起小时候在镇上，确实总是只看到三五成群的爷子们觥筹交错。</p><p>我又再想，会不会很多非硬核游戏玩家的“情侣”，在一开始就没有共事过？所谓的“培养感情”只是不断使用同样类型的消费品来给两人贴上共同的标签，就像《花束般的恋爱》中所描述的那样。</p><p>或许我们最近没有再一起玩游戏，是因为一起在带娃，反馈、挑战、探索和精力消耗都已经足够了。</p><p>换句话说，不是游戏不好玩了，是它的生态位被占据了。</p><h1 id="技术落地"><a href="#技术落地" class="headerlink" title="技术落地"></a>技术落地</h1><p>燕国的地图还是有点长哈，绕了这么大一圈，刚刚讲完了标题中前半部分，现在到后半部分了。</p><h2 id="游戏与技术"><a href="#游戏与技术" class="headerlink" title="游戏与技术"></a>游戏与技术</h2><p>回过头来我很早之前就非常支持《明末》，毕竟是家乡产品。我有很多的感慨，但是看了 STN 之后觉得有他的这个点评就已经够了，有评论道：“分析出我们潜意识意识到的东西然后帮我们意识到表达出来”</p><p>作为野路子出身的程序员，我总是很羡慕好学校以毕业就能进大厂，然后持续在一个领域里不断精进的人。</p><p>正如评价一个游戏的核心指标一定是好不好玩，一个结合时代背景落地创造价值的技术始终是奇技淫巧的自我满足。</p><p>其实很多时候感觉“技术追求”都成了不安现状的遮羞布，但是又不能真的静下心来踏实钻研一个领域的技术，生怕到时候市场不认可或者不能“货与帝王家”。</p><h2 id="执念"><a href="#执念" class="headerlink" title="执念"></a>执念</h2><p>最近看到知乎上有句话： 我们都只是在时间长河中刻舟求剑的可怜人罢了。</p><p>有些人或因主观、客观的原因，被困在“凡是”，但总是有人顺应时代后大权在握，言出法随之后才有资格提出显然的“猫论”。</p><p>个人觉得很多时候所谓的“执念”还是能力和期望不匹配的外在表现。</p><p>比起始终害怕点错工作技能树的技能点，打游戏又不去计较完全算作消耗资源又不会产生收益的“&#x2F;dev&#x2F;null技能点”了。</p><p>学新技术的时候各种怕投入产出比，打起来游戏就是赢一把就睡。</p><h2 id="未来的路"><a href="#未来的路" class="headerlink" title="未来的路"></a>未来的路</h2><p>絮絮叨叨写了很多了，感觉现在想要写出没有语病的句子还挺困难的，从读书时候就开始写总结，定目标然后抛诸脑后。</p><p>好在2025年这一年终于做到了成年以后就一直想做的减肥，减了 30斤，还有 30斤。</p><p>从小就想加入世界知名的公司，不过自问并没有一直持续做什么一步一个脚印的努力，都是在随波逐流。</p><p>之前错过了很多机会，现在路到了脚下，就看怎么走了。</p><h1 id="回归技术"><a href="#回归技术" class="headerlink" title="回归技术"></a>回归技术</h1><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>之前一段时间心态太差，正好只能看看某些时政点评、历史传记、科普读物调整。就落下了背到二十多课的新概念。</p><p>后来发现 《GTC March 2025 Keynote with NVIDIA CEO Jensen Huang》 实在是不可多得的听力材料，沿用着以前背新概念时候的技术路线，先听再跟读。</p><iframe width="560" height="315" src="https://www.youtube.com/embed/_waPvOwL9Z8?si=OHnQcegsgRg5b5qv" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><p>大概七八遍之后吧，基本上能跟上，稍微模糊的懂一点意思，并且大部分句子能够跟读了。</p><p>而且我发现我居然能背出来其中的好些句子了。</p><p>还是那句浅显的金玉良言： 努力不一定成功，但不努力一定不能成功。（学如逆水行舟，不进则退）</p><p>然后就是面试，在进百度之前的那波面试中，有2次英文面试感觉还挺好的，但贪图百度大厂的名头放弃了，时时想到都遗憾不已。</p><p>最近的英文面试中，心态起伏巨大，本来以为是我能力太差以至于无法听懂英伟达的印度老姐的，但是昨天和美国老哥的面试，我感觉多少还是勉勉强强进行下去了。</p><p>实践，唯有实践才是检验真理的唯一标准。</p><p>同时只有以考代练才能真正锻炼出来。</p><div class="note note-info">            <p>8.20 update: 前段时间发现了豆包老师可以提供全英文对话，这得是过去几百元一个小时的服务。高强度对线了几天，现在感觉面试的时候基本上都能听懂问题了。</p>          </div><h2 id="前份工作"><a href="#前份工作" class="headerlink" title="前份工作"></a>前份工作</h2><p>谈不上卧薪尝胆吧，但是谈到这半年的经历确实可以用五味杂陈来形容。少谈点感性，还是回归落实到分析上吧。</p><h3 id="当时背景"><a href="#当时背景" class="headerlink" title="当时背景"></a>当时背景</h3><p>Agora 干了一年后又被裁，找了很多工作。</p><ol><li>面试不少，但比以前的 Offer 率确实低了很多；</li><li>面了很多 DevOps &#x2F; SRE &#x2F; 测试开发 岗位，但加班都是小事，很多还要 On call；</li><li>上述岗位的技术选型其实不重要，最关键的是整体的架构设计层面的掌握，否则只能是熟练工，过几年就被淘汰了；</li><li>很多的岗位的定位听下来都是 On call 的客服。</li></ol><h3 id="Why-Baidu"><a href="#Why-Baidu" class="headerlink" title="Why Baidu"></a>Why Baidu</h3><ol><li>确实没体验过那么大的厂；</li><li>冲着自研大模型和云服务提供厂商；</li><li>去某些小公司也得当客服，不如直接当客服；</li><li>JD 与面试中的技术栈重合度高。</li></ol><h2 id="跑路原因"><a href="#跑路原因" class="headerlink" title="跑路原因"></a>跑路原因</h2><p>那么同样的道理</p><ol><li>Always on call， 发版周期或者自己的代码出问题提供 on call 可以理解，但是面向 on call 只能说是因为人类更便宜才会有这种现象了；</li><li>技术荒废，而且从事的是一眼首当其冲在 AI replacing list，长此以往以后再也找不到工作了；</li><li>工作内容是针对客户的 case，然后盯着这个 case 的 close，但百度云产品太多，很难静下来积累技术，只能维护了一个极大的“High frequency troubleshooting” 库；</li></ol><div class="note note-info">            <p>update: <strong>这几天入行查资料后发现</strong> 不是 hashmap， 这行甚至有个专门的名字 KV cache。</p><p>作用就是和那些客服们现在做的事情一样：之前处理过问题 cache，之后再遇到直接复用。</p><p>没想到吧，抽象的 AI 取代一下就这么具体了，还搁这儿开心的 on call 觉得自己不可替代呢，我们都有光明的未来。</p>          </div><h3 id="新公司抉择"><a href="#新公司抉择" class="headerlink" title="新公司抉择"></a>新公司抉择</h3><p>当时约么三个月内收到了5个 offer ，其中还有某手机芯片领域全球排名第四的芯片公司。</p><p>但首先太多加班太严重了；其次停下来也没有对我个人清晰的发展路线，都是去重复干活，干完就可以被开了；最后数来数去都是和传统运维没有本质区别的工作，我现在这个阶段着实得慎重考虑了。</p><div class="note note-info">            <p>update: 下面是观望了很久的新公司：</p>          </div><ol><li>离家近（高贵的浦西跑步&#x2F;骑车上班的含金量）</li><li>下班时间明确且没有无效加班文化</li><li>做 AI Agent 相关，一个难得的新技术转型切入点</li><li>薪资居然能持平</li></ol><h1 id="螺旋式回归"><a href="#螺旋式回归" class="headerlink" title="螺旋式回归"></a>螺旋式回归</h1><p>入职新公司后发现我的 title 居然也是 “算法工程师”，想起刚毕业成都软件园下沉广场时<br><img src="/2025/08/01/career/@2025_life_is_a_game_ditch_the_tech_obsession/1st_job.png" alt="my initial work"><br>那时我还很年轻，很迷茫，也自以为充满了希望和光明。</p><p>有努力奋进刷课件，也有拖着僵硬疲惫的身体陷入无尽的怀疑。</p><p>时过境迁，7年过去，再次顶着这个 title 的时候，真的是标准的“螺旋”上升，只是这次是真的踩到时代的前沿了。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Record</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mid-2025: Struggling with AI</title>
    <link href="/2025/07/15/ai/mid_2025_struggle_with_ai/@2025_index/"/>
    <url>/2025/07/15/ai/mid_2025_struggle_with_ai/@2025_index/</url>
    
    <content type="html"><![CDATA[<blockquote><p>After intensive AI chats, I’ve stopped writing English blogs. The interactive grammar corrections during our conversations prove that dialogue-based learning trumps one-way content creation.<br>高强度 chat with AI 后发现没必要坚持写英文博客了，因为和 AI 用英文对话后，人家会用标准的语法重复整理一遍我的问题，有交互的学习比单方面的输出效果好多了。</p></blockquote><h1 id="现在时"><a href="#现在时" class="headerlink" title="现在时"></a>现在时</h1><p>现在是 2025年的7月， 号称当前最强代码大模型的 Claude 4 Opus 也已经上线了一个月，而我也高强度使用了两个月百度更早发布的 ERINE-4.5-Turbo-128K-Preview。</p><h1 id="Claude-4-Opus"><a href="#Claude-4-Opus" class="headerlink" title="Claude 4 Opus"></a>Claude 4 Opus</h1><p>Claude 4 Opus 必须开启不计成本的 MAX Mode 才能使用，因此我只能用在新的小项目中，除非公司报销，但是众所周知我现在的公司是有相关自研的，因此报销是更不可能报销的。</p><h2 id="震撼"><a href="#震撼" class="headerlink" title="震撼"></a>震撼</h2><h3 id="去年半自动"><a href="#去年半自动" class="headerlink" title="去年半自动"></a>去年半自动</h3><p>在去年2024年底的时候，一次我有个需要在24h做一个前后端 + LLM chat 的任务，当时肯定是没有 DeepSeek， 用的哪个模型我已经记不得了，但是清楚的记得我是没有做完的，从零开始生成的代码总有点小问题，然后上去一调试半个小时一个小时就没有，整个只能叫脚手架半自动生成工具。</p><h3 id="当前全自动"><a href="#当前全自动" class="headerlink" title="当前全自动"></a>当前全自动</h3><p>但是在 2025年中 的时候，Claude 4 很猛了，我试了一下 “失业程序员副业开发做应用三件套”：记账、todo list和番茄时钟的代码生成，不算思考和填写代码的时间，已经达到了分钟级，本来我还抱着还要亲自上去改的刻板印象，结果前后端代码是直接可以运行的！</p><p>这可以说是很震撼了，毕竟不是演示视频中那种小玩具，我看到生成出来的代码规模和架构已经可以当成完整的商业项目的 demo 了，这可是传统需要一个新手学习半年甚至更久的时间，只有自己亲眼看到才会有这种感觉。</p><p>期间只出现了一个跨域问题，而且都没有我去排查，直接就 fix 了，不禁逼着我想起当年学习的时候花了很多时间才能梳理相关的问题。</p><h2 id="怯魅"><a href="#怯魅" class="headerlink" title="怯魅"></a>怯魅</h2><h3 id="通用知识集"><a href="#通用知识集" class="headerlink" title="通用知识集"></a>通用知识集</h3><p>但是话又说回来，AI 无法写出使用者和普遍知识并集以上水平的代码。</p><p>“失业程序员副业开发做应用三件套”这种设计已然是和 “外包公司商业代码模版” 一样成熟的套路。</p><h3 id="特定领域"><a href="#特定领域" class="headerlink" title="特定领域"></a>特定领域</h3><h4 id="需求与-prompt"><a href="#需求与-prompt" class="headerlink" title="需求与 prompt"></a>需求与 prompt</h4><p>昨晚我让它生成我的一个<strong>需求</strong>： 在性能低下无法联网的电子书上生成一个 .js 的浏览器插件脚本，实现离线的词典<strong>划词翻译</strong>，对标欧路词典。</p><p>我尝试过这种<strong>不含技术细节，只描述</strong>的 prompt， 也试过 step by step 的指<strong>定技术栈甚至把离线词典文件都预先下载</strong>好了，让他用 js 解析的 prompt，但是很遗憾，这种小众需求它连理解都有非常大的困难。</p><h4 id="分析与优化"><a href="#分析与优化" class="headerlink" title="分析与优化"></a>分析与优化</h4><p>在需求上，因为我常年从事的 web backend 相关开发，没有浏览器插件相关的开发经验，我特别好奇的是假如我把 好几个M 大小的文件打包或者说当成静态资源放到某个路径，浏览器是否或者说应该如何读取；</p><p>此外我还一直在问它，我这个需求是否有其他的实现方式，希望他能去帮我搜索一下；</p><p>最后我还亲自找了好几个 GitHub 上已经实现了的 js 或者 python 的离线划词或者词典工程，就让它照着参考如何解析词典文件。</p><h4 id="斗智斗勇"><a href="#斗智斗勇" class="headerlink" title="斗智斗勇"></a>斗智斗勇</h4><p>但是以上前2点直接装死，不管我怎么问它都是在车轱辘话，我是不知道是训练模型的时候对我这种落后时代的离线小众需求不敏感，还是因为网上没有那么多现成的相应的实现导致它避重就轻，我个人是觉得我已经拆解描述清楚了，但是它就一直再演我，消极罢工。</p><p>对于第三点就更摸鱼了，即使我提供了参照的情况并且加了 “please check the download dictionary file, storge and cache complete and usable for js” 等等<strong>一大堆换着花样哄它的 prompt</strong>，并且也在一直强调和表述我的应用场景，我一直需要离线的。</p><p>最后它回馈我的描述词里面是清晰了写明了我的每一个需求点的，但是我最后看它生成出来的代码，里面还是有大量的 http 外部的请求；</p><p>于此同时，还会不厌其烦的自己去生成一个 all English to Chinese dictionary，根本看不到去 parse file 的代码片段。</p><p>斗智斗勇了一个晚上，我发现我的电纸书能装欧路词典，并且它会自动装浏览器划词翻译插件，只是不能用全局屏幕取词罢了。</p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>至少在 2025年总 我的感受是： 当前的 AI 能干掉很多通用领域的新手们了，但是资料少的特定领域还是只能当一个高级搜索引擎。</p><h1 id="MCP"><a href="#MCP" class="headerlink" title="MCP"></a>MCP</h1><p>todo</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Coding</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在 Nas 的 Docker 里面装 vLLM</title>
    <link href="/2025/02/24/ai/@2025_nas_docker_vllm/"/>
    <url>/2025/02/24/ai/@2025_nas_docker_vllm/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文初创建于入职百度之前，写作背景为在声网的时候太多的同事咨询日常事务，且从不看文档，正值 RAG 方兴未艾，号称是大模型幻觉的通用解。</p><p>因此酷爱尝鲜的我就在本地 4070 上部署了 Ollama 跑了个 Deepseek 32B 蒸馏模型，看它一个个字的蹦，也不失为一种乐趣。</p><span id="more"></span><blockquote><p>TODO  最近刚入职，太忙了，而且暂时也没钱买 5090D，同时公司的资源够我研究很久了。</p></blockquote><p>后来啊，后来就迷失在 百度 半夜接客户电话的提心吊胆中惶惶不可终日。</p><p>再后来就是 “RAG 已死，长上下文窗口和 Agent 编排当立“，正如冒出的各个新技术一样，别的不说， Agent 横空出世直接让之前的 “通用解” 变成了笑话。</p><p>当然都是科普安装记录文，谁也别瞧不起谁，就将就挪用了。</p><p>当时的家用 PC </p><blockquote><ul><li>操作系统：Ubuntu 24.10</li><li>CPU: AMD Ryzen 9 5950X 16-Core Processor</li><li>内存：32GB</li><li>显卡：NVIDIA Corporation AD104 [GeForce RTX 4070] (rev a1)</li></ul></blockquote><iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114063761739419&bvid=BV12tPveLEpr&cid=28570224111&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="width: 100%; height: 500px;"> </iframe><p>这是现在公司的电脑</p><blockquote><ul><li>操作系统：fnOS 1.1.4 基于 Debian GNU&#x2F;Linux 12 (bookworm)</li><li>CPU: Intel Core i9-14900KF 24核 32 线程</li><li>内存：4 条共 64 GB 4200MHz DDR5</li><li>显卡：NVIDIA GeForce RTX 4090</li></ul></blockquote><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="操作系统-fnOS"><a href="#操作系统-fnOS" class="headerlink" title="操作系统 - fnOS"></a>操作系统 - fnOS</h2><p>飞牛OS 是基于 Debian 打造的国产 NAS&#x2F;桌面一体操作系统，很多的东西都打包好了，直接跑 AI 相关的工程完全胜任，太好用了以至于治好了我操作系统纠结症。</p><p>官网见 <a href="https://www.fnnas.com/">https://www.fnnas.com/</a>。 </p><p>同理 Ubuntu 或者其他 Linux 发行版自然同理，同时附上老生常谈的： Windows, macOS 用户请自求多福。</p><h2 id="显卡驱动集-Nvidia-Driver-560"><a href="#显卡驱动集-Nvidia-Driver-560" class="headerlink" title="显卡驱动集 - Nvidia-Driver-560"></a>显卡驱动集 - Nvidia-Driver-560</h2><p>登录飞牛后台管理 GUI -&gt; 应用中心 -&gt; 驱动 -&gt; Nvidia-Driver-560</p><p>直接在界面上点击安装即可。</p><p><img src="/2025/02/24/ai/@2025_nas_docker_vllm/01.png" alt="Nas 安装驱动"></p><p>安装完成后 SSH 登录，在 Host 直接运行 <code>nvidia-smi</code> ，能如上图所示识别到显卡信息即为成功。</p><blockquote><p>nvidia-smi 全称是 NVIDIA System Management Interface， 用于监控和查询 GPU 状态。</p></blockquote><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>如果 Host 没有，请自行安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker --version<br>Docker version 28.5.2, build ecc6942<br></code></pre></td></tr></table></figure><h2 id="nvidia-container-toolkit"><a href="#nvidia-container-toolkit" class="headerlink" title="nvidia-container-toolkit"></a>nvidia-container-toolkit</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get install -y nvidia-container-toolkit<br></code></pre></td></tr></table></figure><p>在这个过程中，可能会遇到  <a href="https://nvidia.github.io/libnvidia-container/gpgkey">https://nvidia.github.io/libnvidia-container/gpgkey</a> 相关的 源迁移而导致报错，请自行查阅 AI 解决。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">    docker run --<span class="hljs-built_in">rm</span> --runtime=nvidia --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi<br>Thu Dec 11 02:13:12 2025       <br>+-----------------------------------------------------------------------------------------+<br>| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |<br>|-----------------------------------------+------------------------+----------------------+<br>| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |<br>| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |<br>|                                         |                        |               MIG M. |<br>|=========================================+========================+======================|<br>|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0 Off |                  Off |<br>|  0%   39C    P8              8W /  450W |       1MiB /  24564MiB |      0%      Default |<br>|                                         |                        |                  N/A |<br>+-----------------------------------------+------------------------+----------------------+<br>                                                                                         <br>+-----------------------------------------------------------------------------------------+<br>| Processes:                                                                              |<br>|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |<br>|        ID   ID                                                               Usage      |<br>|=========================================================================================|<br>|  No running processes found                                                             |<br>+-----------------------------------------------------------------------------------------+<br></code></pre></td></tr></table></figure><p>看到 container 里面能成功运行 <code>nvidia-smi</code> 并且和 Host 行为一致，表示着可以在 docker 里面几乎无损的直通驱动了。</p><p><img src="/2025/02/24/ai/@2025_nas_docker_vllm/02.png" alt="关系"><br>安装 nvidia-container-toolkit 会自动安装 libnvidia-container，无需额外关注。</p><h2 id="官方-Docker-镜像"><a href="#官方-Docker-镜像" class="headerlink" title="官方 Docker 镜像"></a>官方 Docker 镜像</h2><p>飞牛OS 自己的服务已经占用了 host 的 8000 端口，得换一个。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 拉取vLLM镜像（适配CUDA 12.x）</span><br><span class="hljs-built_in">sudo</span> docker pull vllm/vllm-openai:latest<br><span class="hljs-comment"># 运行容器（指定GPU、端口、模型，7B模型需至少10GB显存）</span><br><span class="hljs-built_in">sudo</span> docker run --gpus all -p 18000:8000 \<br>  vllm/vllm-openai:latest \<br>  --model lmsys/vicuna-7b-v1.5 \  <span class="hljs-comment"># 替换为你要运行的模型</span><br>  --tensor-parallel-size 1 \       <span class="hljs-comment"># 用几块GPU，按需改</span><br>  --port 18000<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>这里拉取的推理镜像 <code>vllm-openai</code> 中已经包含了 CUDA 套件，否则需要先在 host 中装好。</p>          </div><p>在本地开发机上 curl 进行最简单的请求</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ curl http://192.168.31.78:18000/v1/completions \<br>  -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>  -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">    &quot;model&quot;: &quot;lmsys/vicuna-7b-v1.5&quot;,</span><br><span class="hljs-string">    &quot;prompt&quot;: &quot;Hello vLLM!&quot;,</span><br><span class="hljs-string">    &quot;max_tokens&quot;: 50</span><br><span class="hljs-string">  &#125;&#x27;</span><br><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cmpl-a5b14ea50b0f422ca76d7200492adc33&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;object&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text_completion&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;created&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1765433551</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;lmsys/vicuna-7b-v1.5&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;choices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;index&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; I&#x27;m sorry, I cannot provide a review of vLLM, beyond what I have already written above. However, if you have any questions about vLLM, or any other LL.M programs, I&#x27;d be happy to help&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;finish_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;length&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;stop_reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;prompt_logprobs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;usage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;total_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">56</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;completion_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">50</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;prompt_tokens_details&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br></code></pre></td></tr></table></figure><p><img src="/2025/02/24/ai/@2025_nas_docker_vllm/03.jpg" alt="启动docker"></p><blockquote><p>可以看到，实际上打包成了一个 FastAPI 提供接口服务</p></blockquote><p>至此， vLLM 的服务就安装完成，接下来就是直接学习了。</p><p>PS: 当前的 4090 显卡可以用更加强力的模型</p><blockquote><p> docker run -d –name vllm-openai –gpus all –runtime&#x3D;nvidia <br>  -e NVIDIA_VISIBLE_DEVICES&#x3D;all -e NVIDIA_DRIVER_CAPABILITIES&#x3D;compute,utility <br>  -e HF_HUB_ENABLE_HF_TRANSFER&#x3D;0 <br>  -p 18000:8000 <br>  vllm&#x2F;vllm-openai:v0.6.6 <br>  –model deepseek-ai&#x2F;DeepSeek-R1-Distill-Qwen-32B-AWQ <br>  –quantization awq <br>  –kv-cache-dtype fp8_e4m3 <br>  –tensor-parallel-size 1 <br>  –max-model-len 4096 <br>  –port 8000</p></blockquote><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vLLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI时代 暨 找到工作的第一篇博客</title>
    <link href="/2025/02/24/career/@2025_1st_post_in_ai_era/"/>
    <url>/2025/02/24/career/@2025_1st_post_in_ai_era/</url>
    
    <content type="html"><![CDATA[<h1 id="开头"><a href="#开头" class="headerlink" title="开头"></a>开头</h1><p>很有意思啊，经历了之前的焦虑后，开始恢复状态能正常开始学习了。</p><p>第三次被裁员了，前段时间心态起伏还是很大的，再加上家庭频出状况，很长一段时间不能集中精力学习，不过考虑到当时甚至连游戏都没有兴趣玩，现在也觉得没啥问题，哈哈。</p><p>之前删掉了啰嗦的充满“操作指南”、“操作记录”的博客，想着在 AI 时代没什么用，但是经过最近的学习，反而发现这些才是在 RAG 下宝贵的学习资料。</p><p>因为之前博客写完了，就像中学时代的“笔记”，“错题本”一样被动的放在那里，除非高度规律地规划定期回顾才能被用起来，而现在不同了，我需要迭代自己的 Workflow 了。</p><p><img src="/2025/02/24/career/@2025_1st_post_in_ai_era/screen.jpg" alt="做减法，不要再在桌子上摆很多个屏幕了"></p><h1 id="身体"><a href="#身体" class="headerlink" title="身体"></a>身体</h1><p>以前喋喋不休地在博客、抖音、B站、小红书上打卡，抱团，期望能坚持此前一直没能完成的减肥，但效果甚微。</p><p>大道至简，就和学习本身一样，没有每天落地的实践支持，都是空中楼阁，徒增笑耳。</p><!-- <img src="/2025/02/24/career/@2025_1st_post_in_ai_era/weight_loss_record.jpeg" class=""> --><p><img src="/2025/02/24/career/@2025_1st_post_in_ai_era/weight_loss_record.jpeg" alt="减肥数值记录"></p><h1 id="家庭"><a href="#家庭" class="headerlink" title="家庭"></a>家庭</h1><p>过去的一年里我成为了父亲，又失去了父亲，在这个社会角色定位中，我没有退路了。</p><p>小孩刚出生的时候太轻，妈妈操了太多的心。我当时暗下决心，希望我减肥下来的体重都能加到小孩上。</p><p>然后小孩体重稳步提升，达到了正常体重，反而是我却减得快多了，这是最近最值得开心的事情了。</p><p>迷茫的时候也想想，就像踏实减肥一样，积累到了才会看到成效，毕竟：</p><blockquote><p>没有数值，我只看到了努力和汗水。</p></blockquote><h1 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h1><p>AI 带来了很多改变啊，在首页里面已经有了足够的碎碎念了。</p><p>这段时间深度体验 + 部署之后，发现现阶段的 AI 在通识方面已经无敌，但在专业领域完全不能令我满意。</p><p>如果说以前的搜索引擎是纯粹只会认关键字的外行，现在的 AI 已经是过目不忘的学徒，能快速解决描述清晰且典型的问题，离指导工作者的行业专家还有一段距离。</p><p>这也是我现在更有动力更新博客的原因，期望能在 RAG 的帮助下打造成我的个人知识库。</p><h1 id="工作-（补于-2025年3月-找到工作后）"><a href="#工作-（补于-2025年3月-找到工作后）" class="headerlink" title="工作 （补于 2025年3月 找到工作后）"></a>工作 （补于 2025年3月 找到工作后）</h1><p>很神奇啊，找了三个月，终于找到工作了。</p><p>日子过得就像梦一样，从最开始知道要被辞退时候的惴惴不安，到后来排满了的疯狂面试，再到临近入职的不真实感，明明是一个季度内发生的，却感觉隔离地太彻底了。</p><p>期间心情相当大起大落，抛开各种变故的影响不谈，光是每次面试之后的抉择就觉得有够累人的，不过回想起来还是觉得每次样本训练就是一次成长。</p><p>前几天还能文思泉涌地持续码字，现在下班打开电脑，又回到上学时候那种提笔忘字的状态。</p><p>终于进入了世界一流知名度的公司，小时候幻想过无数次的场景，真的实现到自己身上的时候又全是不真实感。</p><p>虽然依旧是一颗螺丝钉，但是现在真的满脑子都是“我奋斗了18年才和你坐在一起喝咖啡”。</p><p>马上工作就快十年了，不知道其中浪费了多少年，总想做点有意义的事情，不要再混天过日了。</p><p>大概在高中的时候感悟出来了能<strong>看到努力的方向</strong>和<strong>持之以恒的努力</strong>是两项最大的天赋，有点晚了，</p><p>前30年也走了不少弯路，不过好在 AI时代 更多的信息差会被抹平，终于能赶上这班车了。</p><p>以下，贴上找工作期间（2024年12月～2025年3月）的自我介绍，仅做纪念。</p><hr><h3 id="Hi-there-👋-This-is-Roy-Lee-✨"><a href="#Hi-there-👋-This-is-Roy-Lee-✨" class="headerlink" title="Hi there 👋 This is Roy Lee! ✨"></a>Hi there 👋 This is Roy Lee! ✨</h3><p><a href="https://space.bilibili.com/776431"><img src="https://img.shields.io/badge/-Bilibili-00A1D6?style=flat&logo=bilibili&logoColor=white" alt="Bilibili"></a> <a href="https://www.linkedin.com/in/%E7%BA%A2%E7%9D%BF-%E6%9D%8E-a2a612157/"><img src="https://img.shields.io/badge/-LinkedIn-blue?style=flat&logo=Linkedin&logoColor=white" alt="Linkedin"></a> <a href="https://gou7ma7.github.io/"><img src="https://img.shields.io/badge/-Blog-red?style=flat&logo=Blog&logoColor=white" alt="Blog"></a></p><hr><h3 id="About-Me"><a href="#About-Me" class="headerlink" title="About Me"></a>About Me</h3><p>I’m Roy Lee (Li Hongrui in Chinese), a DevOps and Python backend engineer with experience in multiple NASDAQ-listed companies. My most recent role was at <strong>Agora (NASDAQ: API)</strong>, where I worked as a Developer Productivity Engineer.</p><p>After being laid off at the end of 2024, I’ve been actively seeking opportunities in <strong>DevOps</strong>, <strong>Python Backend Development</strong>, and <strong>Test Automation Engineering</strong>. My career began in UI automation testing, and I’ve since transitioned into DevOps, focusing on improving development efficiency and infrastructure.</p><p>My early career experiences are quite repetitive, so I’ll share a video of my talk at the PyCon developer conference instead of detailing them here. It provides a comprehensive overview: <a href="https://www.bilibili.com/video/BV1Wv411b7Gm">My PyCon Shenzhen Talk: Joining a Tencent-backed Mid-sized Company, Summarizing My First 2 Years of Work Experience, and Advice for Newcomers</a>.</p><p>我是 李红睿 （Li Hongrui），曾任职于多家纳斯达克上市公司，担任 DevOps 和 Python 后端工程师。最近一份工作是在 <strong>声网（Agora，NASDAQ: API）</strong> 担任研发效率开发工程师。</p><p>2024 年末被裁员后，我一直在积极寻找 <strong>DevOps</strong>、<strong>Python 后端开发</strong> 和 <strong>测试开发</strong> 相关的职位。我的职业生涯从 UI 自动化测试开始，后来逐渐转向 DevOps，专注于提升研发效率和基础设施优化。</p><p>早期经历重复度很高，因此放一个我在 pycon 开发者大会中的演讲视频，里面有详细的介绍，就不在此赘述，<a href="https://www.bilibili.com/video/BV1Wv411b7Gm">我在pycon深圳的演讲：进腾讯投资的中厂、总结前2年工作心得和对新人的建议</a>。</p><hr><h3 id="Seeking-a-New-Job"><a href="#Seeking-a-New-Job" class="headerlink" title="Seeking a New Job"></a>Seeking a New Job</h3><p>I’m currently looking for roles in <strong>DevOps</strong>, <strong>Python Backend Development</strong>, and <strong>Test Automation Engineering</strong>. If you’re hiring or know of any opportunities, feel free to reach out!</p><p>我正在寻找 <strong>DevOps</strong>、<strong>Python 后端开发</strong> 和 <strong>测试开发</strong> 相关的职位。如果你有合适的职位或机会，欢迎联系我！</p><hr><h3 id="Skills-Learning"><a href="#Skills-Learning" class="headerlink" title="Skills &amp; Learning"></a>Skills &amp; Learning</h3><ul><li><strong>Strengths</strong>: Proficient in Python, end-to-end development experience, quick learner, adaptable. </li><li><strong>Weaknesses</strong>: Broad but not deep technical stack; I’m actively working on deepening my expertise in key areas.</li><li><strong>Current Focus</strong>: AI in DevOps (AIOps), Kubernetes, and Python backend development.</li><li><strong>English</strong>: Fluent in business English communication (emails, meetings), though technical vocabulary needs more practice in work scenarios.</li></ul><br><ul><li><strong>优点</strong>: 熟悉 Python 生态，有多段端到端开发经验，在UI自动化测试、运维开发、k8s云平台搭建等业务均有 0-1 的经验，学习能力强，适应能力强，最后 OKR 都完成了。</li><li><strong>缺点</strong>: 技术栈广而不深，急需一份相对稳定的业务、或者足够有深度的业务来精进技术，使我达到“行业前列”的水准。</li><li><strong>当前重点</strong>: AI 在 DevOps 中的应用（AIOps）、Kubernetes 和 Python 后端开发。</li><li><strong>英语</strong>: 日常的邮件、口语会议交流没问题，能进行商务英语沟通，但专业词汇还需要业务场景的锻炼才能更加熟练。</li></ul><p><img src="https://gou7ma7.github.io/images/heatmap.png" alt="heatmap"></p><p>The tech industry is rapidly evolving, especially with the rise of AI. During my job search, I’ve realized that simply relying on past experiences isn’t enough. In one interview with a top-tier global company, I aced the technical rounds but was challenged during the leadership interview: “Don’t just talk about AI in your side projects. Show us how you can learn and integrate new technologies into our needs.” This was a wake-up call for me. I’ve decided to embrace the AI revolution, whether it’s deploying AI products or using AI to optimize traditional DevOps workflows.</p><p>I’m now focused on building a solid foundation while staying ahead of industry trends. I’ve even deleted my 4-year-old blog to start fresh, rediscovering the joy of learning and documenting my journey. Check out my <a href="https://gou7ma7.github.io/2025/02/05/heatmap/index/">Skill Tree</a> to see my learning roadmap.</p><p>最近找工作时，发现很多岗位已经有了 AI 相关的需求。最近面某家国际一流公司，前面技术面都秒过了，结果领导面的时候被质疑了：”我问你 AI 相关的经历，不是总听你说你用 AI 做了啥副业，我更想听你怎么快速学习我们需要的技术，怎么把它们整合到现有业务里。”</p><p>虽然缺乏业务环境导致我只能在我的副业工作流里面落实 AI ，但既然企业想要这方面的人才，那我至少也应该先自行学习，那位领导所说的“技术对每个人都是公平的”，我深以为然，并且要落实。</p><p>我现在一边打基础，一边追新趋势。连写了 4 年的博客都删了，重新开始学习打卡，感觉又找回了当初学习的那种新鲜劲儿。进度在<a href="https://gou7ma7.github.io/2025/02/05/heatmap/index/">技能树</a><br><a href="https://gou7ma7.github.io/2025/02/05/heatmap/index/">https://gou7ma7.github.io/2025/02/05/heatmap/index/</a></p><hr><h3 id="Let’s-Connect"><a href="#Let’s-Connect" class="headerlink" title="Let’s Connect!"></a>Let’s Connect!</h3><p>Feel free to reach out via <a href="https://www.linkedin.com/in/%E7%BA%A2%E7%9D%BF-%E6%9D%8E-a2a612157/">LinkedIn</a> or <a href="https://space.bilibili.com/776431">Bilibili</a>. Let’s collaborate and grow together!</p><p><a href="https://github.com/anuraghazra/github-readme-stats"><img src="https://github-readme-stats.vercel.app/api/top-langs/?username=gou7ma7" alt="Top Langs"></a></p><p><img src="https://github-readme-stats.vercel.app/api?username=gou7ma7&show_icons=true" alt="Anurag&#39;s GitHub stats"></p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Review</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Human Agent -&gt; AI Agent Learning Progress Heatmap</title>
    <link href="/2025/02/05/heatmap/@2025_index/"/>
    <url>/2025/02/05/heatmap/@2025_index/</url>
    
    <content type="html"><![CDATA[<h2 id="To-be-refactored"><a href="#To-be-refactored" class="headerlink" title="To be refactored."></a>To be refactored.</h2><p>After being laid off for the third time and going through dozens of interviews, I need to deeply reflect on how to establish myself in this industry.<br>第三次被裁员后，经历了几十场面试后，需要深入思考自己应该如何立足这个行业。</p><p>The demand for AI-related positions is increasing, mainly divided into deploying AI products themselves or using AI to optimize traditional DevOps processes.<br>AI 相关的岗位要求越来越多，看下来主要分为部署 AI 产品本身，或者使用 AI 优化传统 DevOps 流程。</p><span id="more"></span><p>At the beginning of interviews, I would gloss over with “no project experience in past business” and thought I should solidify fundamentals rather than chase trends.<br>刚开始面试的时候，我还在以”过往的业务经历中没有项目实践一笔带过”，并且想着应该夯实基础，而不是追赶潮流。</p><p>Until interviewing with a top global company - I aced the technical rounds but was challenged during leadership interview: “Don’t talk about AI implementation in your side projects, I want to hear about your learning and integration of new technologies we need” - exposing my lack of AI competencies required for the role.<br>直到面某全球一流公司时，前面技术都面秒过，却在领导面的时候，被质疑”不要讲 AI 在你的副业中的落地，我想听到的是你对我们需要的新事物的学习和整合”代表的岗位需要的 AI 相关的能力不足。</p><p>This was a wake-up call. I always wanted to join companies beyond routine business coding, yet wasn’t prepared for open-ended questions when they came.<br>这对我造成了极大冲击，总是想找个不是整天光写业务的公司，但真的问开放问题的时候又没准备好。</p><p>Interviews test job fit beyond just skills. While I preach about keeping up with times, I default to “never used in production” when challenged.<br>面试本身是对这个岗位要求的匹配，不只是能力的筛选，平时总是说到要跟上时代不能被淘汰，到了这个时候又搪塞以”工程上没用过”。</p><p>This must change. Whether for future interviews or daily learning, isolated self-study won’t cut it anymore.<br>I have to delete the blog I’ve been writing for the past 4 years and start fresh with checking in for learning. It seems like I can regain that fresh feeling I had when I first started learning.<br>不能这样了，不管是以后的面试，还是平时学习，闭门造车始终是不行的。<br>不得不删除之前写了 4年 的 Blog，重新开始打卡学习，看来也能找回刚学习的时候那种新鲜感了。</p><div id="heatmap" style="width: 100%;height:800px;"></div><!-- 引入热力图组件 --><script type="module" src="/js/heatmap.js"></script><p>The learning progress is divided into five stages: Beginner, Explorer, Theorist, Practitioner, and Proficient.</p><ul><li><strong>Beginner</strong>: Installed&#x2F;Used the component.</li><li><strong>Explorer</strong>: Written an article about it.</li><li><strong>Theorist</strong>: Understood the underlying principles.</li><li><strong>Practitioner</strong>: Applied the component effectively in projects.</li><li><strong>Proficient</strong>: Mastery of the component, capable of teaching and leading others in its use.</li></ul><h1 id="the-second-half-of-2025"><a href="#the-second-half-of-2025" class="headerlink" title="the second half of 2025"></a>the second half of 2025</h1><div class="markmap-wrap"                 >      <script type="application/json">{"content":"AIOps","children":[{"content":"<a href=\"https://roadmap.sh/python\">Python</a>","children":[{"content":"&#x5b50;&#x8282;&#x70b9;","children":[],"payload":{"tag":"li","lines":"2,3"}}],"payload":{"tag":"li","lines":"1,3"}},{"content":"<a href=\"https://roadmap.sh/ai-engineer\">ai-engineer</a>","children":[],"payload":{"tag":"li","lines":"3,4"}},{"content":"<a href=\"https://roadmap.sh/devops\">DevOps</a>","children":[],"payload":{"tag":"li","lines":"4,5"}}],"payload":{"tag":"li","lines":"0,5"}}</script>      <script type="application/json">{}</script>    </div><h1 id="Abandoned"><a href="#Abandoned" class="headerlink" title="Abandoned"></a>Abandoned</h1><ul><li>Selenium 异步标签页池：使用 Puppeteer&#x2F;Playwright 完成，避免业务耦合。</li><li>StudyFlow 可视化技能树项目：<ol><li>先将需要打卡的知识点放到一个 data.json</li><li>再使用 Echarts 渲染一个棵 js 代码中表达的树 （后改成热图）</li><li>进而在 markdown 中被引用</li><li>同时使用 Puppeteer 渲染这段 js 代码，将生成的这棵树的 .png 文件保存到 source&#x2F;images 目录下，能够用做文章头图，或者被首页引用</li><li>至于打卡部分，就使用 iOS 原生的日历app，再定期总结规划即可，没有必要非要形式上搞一个前后端工程</li></ol></li><li>Study Map: 逛 v2ex 时发现 <a href="https://roadmap.sh/">https://roadmap.sh/</a> 惊为天人，已经完成了我一直想要的游戏化一样的学习指导和进度跟踪，学习最重要的就是不能闭门造车。</li></ul><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    
    <tags>
      
      <tag>Skill</tag>
      
      <tag>AIOps</tag>
      
      <tag>DevOps</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在工作6年之际总结业务与技能点</title>
    <link href="/2024/05/18/career/@2024_review_2024/"/>
    <url>/2024/05/18/career/@2024_review_2024/</url>
    
    <content type="html"><![CDATA[<p>再也不是毕业在即两眼一黑，更不是初入职场惶恐不安的状态了。<br>不知不觉已经6年工作六年，在3年的时候拍了<a href="https://www.bilibili.com/video/BV1b7411B7YR">第一个 vlog </a>，那个时候说三年应该跨过新手期，深耕一个领域，现在看来没有辜负当时的期待。<br>迄今，我的职业生涯从成都小公司做 python 后端 + 爬虫，经过深圳上海做 效能 &#x2F; DevOps，现在定居上海，基本快完成从小就“想进入世界一流公司的梦想”了。</p><span id="more"></span><h1 id="迷茫的学生时代"><a href="#迷茫的学生时代" class="headerlink" title="迷茫的学生时代"></a>迷茫的学生时代</h1><p>中学就在开始参加竞赛，但基于我懒散随性的性格，也没搞出什么名堂，当时某个拿满分的队友，毕业就进入当时还没有那么出名的字节跳动（当时好像还叫头条），我却连自己能不能进入这个行业都在怀疑。</p><p>大学的时候曾有机会跟着老师做地质相关的图形图像处理，最后也只夸夸其谈没有坚持下来。<br>临近毕业还去面试完美世界的客服，回过头来还是觉得当时太浮躁了。</p><h1 id="惶恐的初入职场"><a href="#惶恐的初入职场" class="headerlink" title="惶恐的初入职场"></a>惶恐的初入职场</h1><p>没有参与校招，前三份工作都是成都的（符合对西南柬埔寨刻板印象的）小公司，可以说我的起点很低了。<br>符合城情的试用期不买社保，根本不存在的职业规划和晋升途径。在我多次痛苦挣扎之后均都在差不多第3个月的时候跑路，导致我当时的简历乱七八糟，向未来能看到的只有迷雾。</p><p>摸索中学到了：<br>1st ： python 后端开发， 团队职业分工，调用别人 api；<br>2nd ： 网页模拟点击操作， 爬虫， 开放 api， 封装代码， 数据展示相关的 dashboard；<br>3st ： 权责分明， 破除名校光环， 职场自保， 对梦想的方向坚定不移；</p><h1 id="辗转的适应社会"><a href="#辗转的适应社会" class="headerlink" title="辗转的适应社会"></a>辗转的适应社会</h1><p>挣扎过后觉得日子不能这样过下去了。几经波折找到成都一家正规的做机票代理的公司。</p><p><strong>成都公司</strong>： docker 打包， restful api， 微服务，多线程，重构代码。</p><p>再后来就是疫情来了被裁，发现成都根本找不到工作，然后接到了深圳一家上市公司的 offer ，现在无时不刻不在觉得这是一个影响深远的决定。</p><p>到了深圳公司。<br>一开始业务是在测试开发相关，是让我解决 过量膨胀的 testcase 的问题，加上探索新一代的 testcase runner（基于 nlp, cv, or ?），以及作为甲方私有化地部署购买的服务；<br>随着业务的发展，进而为开始搭建 客户端app 流水线，维护物理agent机器，以及串起来 CI 相关的各种组建，再加上 CD 相关的服务；</p><p><strong>深圳公司</strong>： Jenkins， php， vue， cicd。</p><p>一个机缘巧合下来上海了，又是一个全新的领域，虽然岗位还是叫 DevOps，但是按照某些公司的定位应该是 SRE，即我认为的“线上稳定性保证”。</p><p><strong>上海公司</strong>：kubernetes， 云服务商，continuous development， 发版平台。</p><h1 id="成熟且明确的规划"><a href="#成熟且明确的规划" class="headerlink" title="成熟且明确的规划"></a>成熟且明确的规划</h1><p>也是一个缘分，被上家公司裁员之后，本来拿出了半年准备面试，结果没几天接到的第三个 offer 就感觉挺合适的，就直接去了，社保都无缝衔接。</p><p>背景相当于本来有一个团队负责类似 客户端 &#x2F; 大前端 cicd 这种业务线，然后整个团队都没了。<br>于是在开始的半年我就用了近乎全部的精力去当客服，少的时候几十个，多的时候同时面对上百个人的同步咨询。<br>还能用的服务，把文档和使用文档整理出来；不能用的服务，排期进行恢复。<br>那段时间压力非常大，总会有几个人同步的消息请求过来，不管是去处理谁的事情了，总有人没法得到相应。经常凌晨四五点就醒了睡不着，主要是人只有一个，要做的事情却太杂了。</p><p>现在很多同事经常都和我打趣说不知道我当时是怎么扛下来的，以及当时终于盼来我之后，经常看我状态是否是 （已跑路）。<br>当时下至一线同事，上至HRBP看到我来了都笑嘻嘻地表示终于有人填坑。<br>很多业务开发同事开始报复性提需求，也经常把我当客服发泄自己搞不定又根本不该我管的来分散我的精力。<br>多亏了当时的领导，帮我挡下了很多不合理的需求，以及授权我在文档详实的情况下拒绝同事期待的手把手帮教写代码的无理需求。</p><p>接下来做了一次组织架构调整，也招到了人，终于才能有时间看看 《深入理解计算机系统》；<br>点一下从成都正规公司就早有耳闻的 Goland 技能点。</p><p>我现在也算有了相对清晰的职业规划。<br>首先我真的是一个不挑业务的人，不知道为什么总有人听到我说这个的时候会感到诧异，工作这么多年，哪次不是收拾行囊进入新的业务领域，不都是软件开发工程么，有的只是业务上的区别。<br>其次大方向是 内部平台（或者说所谓的中台），不管是所谓的发版平台，效能 统计 &#x2F; 展示 &#x2F; 运维 &#x2F; 自动化平台，或者说 all in one 的 CICD 流水线平台开发；<br>亦或者 云上 SRE k8s 这一套。<br>这些都是我多年的业务经验领域，比较熟悉了，出现新的工具上手也很快。<br>当然如果让我回去做测开也是一样的，因为我始终觉得 测试，或者说质量保证是 效能 &#x2F; DevOps 很重要的一环。<br>最后我是真的不挑业务，有机会做什么大数据，AI相关开发当然更好。</p><p>随着 Copilot &#x2F; ChatGPT 的普及，技术上手门槛只会越来越低，像刚毕业那会儿学个新东西还是翻文档，再在耐不住的时候狂看相关视频，痛苦地搞个个把月，但现在直接就可以上手业务代码，一边翻译一边询问，哪怕是从来没有用过的语言，在见多识广的 AI 帮助下，直接先写项目。<br>等积累了一定经验，再回头系统的找资料学习，先不说提升的效率，基本上都不再会有以前那种需要摸索找切入点，然后痛苦的在繁杂而陌生的知识图谱中打转的学习状态了。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Review</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DevOps Toolchain Integration Setup</title>
    <link href="/2023/04/30/devops/@2023_devops_toolchain_integration/"/>
    <url>/2023/04/30/devops/@2023_devops_toolchain_integration/</url>
    
    <content type="html"><![CDATA[<h1 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h1><p>作为个人工作中实际用到的DevOps相关工具链的整合搭建，同时也作为新手上手DevOps的Quick Setup。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>长话短说:</p><ul><li><p>数据分析师: 作为一名<strong>数学专业</strong>的划水学生，毕业之后无比<strong>憧憬</strong>能成为一名“数据分析师”，然后被<strong>忽悠</strong>到“信老师”（化名，具体内容可以参见<a href="https://www.bilibili.com/video/BV1Wv411b7Gm">我的一个视频总结</a>）旗下工作；</p></li><li><p>爬虫：老师告诉我，<strong>数据平台还没搭建好</strong>，这样吧，你先自己去<strong>公网上爬取数据</strong>；</p></li><li><p>爬虫 *2： 第一份正式的工作，技术栈是<strong>自动化</strong>的请求接口 &#x2F; <strong>操作浏览器界面</strong>完成业务；</p></li><li><p>测试开发 + DevOps：凭借上述后者，找到了<strong>UI自动化测试开发</strong>的工作；再在工作中要用到<strong>整合流水线</strong>为业务开发同事提供服务，于是职位变成了DevOps；</p></li><li><p>DevOps：来到上海成为专职DevOps，负责Daily CI&#x2F;CD &amp; Release platform 的搭建。</p></li></ul><p>之前的工作中部分组件是我去的时候已经安装、配置好了的，因此在这里把用到的工具链进行全流程的安装，回顾并系统的梳理技术栈，同时也作为新手上手DevOps的Quick Setup。</p><span id="more"></span><h1 id="机器"><a href="#机器" class="headerlink" title="机器"></a>机器</h1><p>Ubuntu 实体机 *2 （不要用WSL）</p><p>一个作为master，另一个作为node，搭建一个最小的集群。</p><h1 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h1><p>之前业务上主要使用的是阿里云容器服务Kubernetes版（Alibaba Cloud Container Service for Kubernetes，简称容器服务ACK）</p><p>同时在私有化部署的时候使用<a href="https://kubesphere.io/zh/">kubesphere</a>，本文主要使用后者进行物理机上的部署。</p><p><a href="https://gou7ma7.github.io/2023/05/11/devops/Kubernetes/">Kubernetes Setup in Local Physical Servers</a></p><h1 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h1><p>The package manager for Kubernetes</p><p>简单来说，我的包管理方式经过一下迭代</p><ol><li>exe &#x2F; other executable file &#x2F; tar &amp; scp;</li><li>Docker Image;</li><li>Helm Charts;</li></ol><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Setup</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>不要用WSL，否则会变得不幸</title>
    <link href="/2023/04/30/devops/@2023_no_wsl/"/>
    <url>/2023/04/30/devops/@2023_no_wsl/</url>
    
    <content type="html"><![CDATA[<p>有位前辈用“Linux本身不要钱，但是你（折腾）的时间更费钱”来形容Linux上可能遇到的适配问题，从而表达自己对该系统又爱又恨的感情。</p><p>而寄宿在Windows上的WSL，更是将这个说法发挥到极致。</p><p>在我自己从头搭建Kubernetes工具链的时候，由于家境贫寒，本想就着手上4台老旧PC搭建个基本能用的集群就行，结果在Windows里面装WSL，以及WSL里面装Kubernetes的时候，遇到太多看不到尽头的问题，遂放弃。</p><p>目前我的解决方案是安装Ubuntu系统到其中2台PC，至少先跑起来一个最小的主从集群。</p><p>而本次我本身就是为了学习才搭建环境，因此记录下遇到的WSL相关的问题，以便学有余力的时候更加透彻的掌握操作系统相关的知识。</p><span id="more"></span><h1 id="WSL的适用范围"><a href="#WSL的适用范围" class="headerlink" title="WSL的适用范围"></a>WSL的适用范围</h1><p>写写Python代码，搭建普通的前后端应用，WSL是非常合适的，甚至避免了在Windows上安装软件的麻烦事。</p><p>但是在涉及到底层的东西，比如说虚拟化、容器化、集群化等这种需要用到“网卡”之类硬件的配置的时候，WSL这类基于Hyper-v的“精简版”虚拟机就会变得缺胳膊少腿，有早年用过“番茄花园”这种精简版Windows打游戏然后缺少组件经历的朋友就能体会到我的感受。</p><h1 id="最好的是物理机，其次是真正的虚拟机"><a href="#最好的是物理机，其次是真正的虚拟机" class="headerlink" title="最好的是物理机，其次是真正的虚拟机"></a>最好的是物理机，其次是真正的虚拟机</h1><p>这几天我一直在满是坑的泥泞中匍匐，很多问题要么是没有通用解法，要么是试下来根本不管用。</p><p>最后学习阶段只推荐VMware、VirtualBox这种成熟得不能再成熟的真正的虚拟机，如果不信欢迎自行尝试。</p><h1 id="systemd与systemctl"><a href="#systemd与systemctl" class="headerlink" title="systemd与systemctl"></a>systemd与systemctl</h1><p>systemd是一个Linux系统的初始化系统和服务管理器;</p><p>而systemctl是systemd的一个命令行工具，用于控制systemd系统和服务管理器。</p><p>systemctl可以启动、停止、重启、重载、状态检查、启用或禁用系统服务。</p><p>WSL2本身是由Windows负责运行的，因此使用tree或ps命令时会看到根进程不是systemd，这将导致无法启动Linux系统服务的守护进程(deamon)。当我们执行systemctl命令的时候，会显示出我们的init system (PID 1)并非systemd，而是微软提供的init system。</p><p>即使在&#x2F;etc&#x2F;wsl.conf添加systemd&#x3D;true配置等操作也会有各种问题。</p><h2 id="service代替systemctl"><a href="#service代替systemctl" class="headerlink" title="service代替systemctl"></a>service代替systemctl</h2><p>虽然有些时候能够通过service代替systemctl，但是有些时候会出现<code>Failed to connect to bus: No such file or directory</code>的错误。</p><p>比如我跑一个自动安装docker &#x2F; 自动开启ssh的脚本的时候，由于源头默认提供的脚本是使用systemctl的，还是绕不开这个问题。</p><p>如果我去批量替换别人的脚本，又会带来新的问题。</p><h1 id="WSL2无法连接网络"><a href="#WSL2无法连接网络" class="headerlink" title="WSL2无法连接网络"></a>WSL2无法连接网络</h1><h2 id="Windows-automatically-generates-resolv-conf-file-with-wrong-nameserver"><a href="#Windows-automatically-generates-resolv-conf-file-with-wrong-nameserver" class="headerlink" title="Windows automatically generates resolv.conf file with wrong nameserver"></a>Windows automatically generates resolv.conf file with wrong nameserver</h2><p><a href="https://stackoverflow.com/questions/62314789/no-internet-connection-on-wsl-ubuntu-windows-subsystem-for-linux">https://stackoverflow.com/questions/62314789/no-internet-connection-on-wsl-ubuntu-windows-subsystem-for-linux</a><br>Locate the file by running the following command:</p><p><code>sudo vim /etc/resolv.conf</code></p><p>You will see the following in the file:</p><h1 id="This-file-was-automatically-generated-by-WSL-To-stop-automatic-generation-of-this-file-add-the-following-entry-to-etc-resolv-conf"><a href="#This-file-was-automatically-generated-by-WSL-To-stop-automatic-generation-of-this-file-add-the-following-entry-to-etc-resolv-conf" class="headerlink" title="This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to &#x2F;etc&#x2F;resolv.conf"></a>This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to &#x2F;etc&#x2F;resolv.conf</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># [network]</span><br><span class="hljs-comment"># generateResolvConf = false</span><br>nameserver xxx.xx.xx<br></code></pre></td></tr></table></figure><p>Change the nameserver value to 8.8.8.8 and save the file. You should now be able to connect to the internet.</p><h2 id="winsock"><a href="#winsock" class="headerlink" title="winsock"></a>winsock</h2><p><a href="https://github.com/microsoft/WSL/issues/3438#issuecomment-41051857">https://github.com/microsoft/WSL/issues/3438#issuecomment-41051857</a><br>Open Command Prompt as an Administrator and type these commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">netsh winsock reset <br>netsh int ip reset all<br>netsh winhttp reset proxy<br>ipconfig /flushdns<br>Reboot your machine.<br></code></pre></td></tr></table></figure><p>完成之后一定重启WSL，否则修改不生效。</p><h1 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h1><p>WSL2可以直接用Windows的命令行直接进入，也可以通过VSCode的WSL插件直接本地连接WSL；</p><h2 id="无法Set-Bridge-Network"><a href="#无法Set-Bridge-Network" class="headerlink" title="无法Set Bridge Network"></a>无法Set Bridge Network</h2><p>在正统的虚拟机配置设置Bridge Network都是点一键就能拿完成的工作，我无法在WSL上完成，虽然各种教程都说在Windows上的Hyper-v管理器上设置一下就好了，但是如果真的是这样的话，就不会有这篇文章了。</p><h2 id="kex-exchange-identification-Connection-closed-by-remote-host"><a href="#kex-exchange-identification-Connection-closed-by-remote-host" class="headerlink" title="kex_exchange_identification: Connection closed by remote host"></a>kex_exchange_identification: Connection closed by remote host</h2><p>在WSL2中开启sshd服务之后，连接自己机器上的WSL2只需要通过<code>ssh localhost</code>就可以；</p><p>连接局域网中另一个PC物理机上的WSL2就会出现标题标错，还有更离谱的timeout，我尝试过很多，就没成功过（多半是因为上面Set Bridge Network没成功导致的）。</p><h1 id="Transport-endpoint-is-not-connected"><a href="#Transport-endpoint-is-not-connected" class="headerlink" title="Transport endpoint is not connected"></a>Transport endpoint is not connected</h1><p>导致这个问题的原因太多了，不断重启LxssManager服务可能会暂时可用一下，我就是被这个问题搞得彻底放弃的。</p><p>LxssManager是Windows 10中的一个服务，它支持运行本机ELF二进制文件。该服务提供在Windows上运行ELF二进制文件所需的基础结构。WSL是Windows Subsystem for Linux的缩写，它是一个允许在Windows 10上运行Linux二进制文件的兼容层。LxssManager是WSL的一部分，它负责管理WSL的Linux发行版。</p><h1 id="swap"><a href="#swap" class="headerlink" title="swap"></a>swap</h1><p>首先部署Kubernetes的机器不能开启swap，因为在写入虚拟内存的时候会影响性能和造成系统卡顿；</p><p>于是在实体机上只需要<code>sudo swapoff -a</code>简单一步的操作，在WSL上死活不起作用，推测是WSL的swap是由Windows上的某个专门负责虚拟化的服务进行配置的，然后由于问题太过偏门，尝试了之后没有找到轻松有效的方法。</p><h1 id="Ubuntu-桥接接入局域网固定IP"><a href="#Ubuntu-桥接接入局域网固定IP" class="headerlink" title="Ubuntu 桥接接入局域网固定IP"></a>Ubuntu 桥接接入局域网固定IP</h1><h2 id="入网方式"><a href="#入网方式" class="headerlink" title="入网方式"></a>入网方式</h2><p>一般虚拟机软件都提供多种网络模式，主要有：</p><p>NAT模式： 虚拟机没有直接接入局域网，和集群里面的Node宿主机互相ping不通，<strong>不选</strong></p><p>Bridged Adapter模式：即桥接模式，为虚拟机模拟出一个独立的网卡，有独立的IP地址接入局域网，<strong>选</strong></p><h2 id="固定IP"><a href="#固定IP" class="headerlink" title="固定IP"></a>固定IP</h2><p>当虚拟机使用桥接模式接入局域网之后，就和物理机Ubuntu的设置一样了。</p><p>Ubuntu 18.04 LTS之后的版本使用&#x2F;etc&#x2F;netplan&#x2F;下得文件来配置网络，我这里叫01-network-manager-all.yaml。</p><p>首先使用<code>ifconfig</code>查看当前机器的网络情况，找到桥接的网卡名称，我这里是<code>enp0s3</code>；</p><p>然后使用<code>sudo vim /etc/netplan/01-network-manager-all.yaml</code>打开配置文件，添加如下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Let NetworkManager manage all devices on this system</span><br>network:<br>  ethernets:<br>    enp0s3:  <span class="hljs-comment">#配置的网卡的名称</span><br>      addresses: [192.168.31.50/24]  <span class="hljs-comment">#配置的静态ip地址和掩码</span><br>      dhcp4: no  <span class="hljs-comment">#关闭DHCP，如果需要打开DHCP则写yes</span><br>      optional: <span class="hljs-literal">true</span><br>      routes:<br>        - to: 0.0.0.0/0<br>          via: 192.168.31.1  <span class="hljs-comment">#网关地址</span><br>      nameservers:<br>         addresses: [192.168.31.1]  <span class="hljs-comment">#DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开</span><br>  version: 2<br>    <span class="hljs-comment"># renderer: NetworkManager</span><br>  renderer: networkd  <span class="hljs-comment">#指定后端采用systemd-networkd或者Network Manager</span><br></code></pre></td></tr></table></figure><p>networkd和NetworkManager都是用于管理网络接口的后端。networkd是systemd的一部分，它是一个轻量级的网络管理器，可以在Ubuntu 18.04及更高版本中使用。它使用Netplan配置文件来配置网络接口。NetworkManager是一个更高级的网络管理器，可以在Ubuntu 16.04及更高版本中使用。它提供了一个GUI界面，可以方便地配置网络接口。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Setup</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes Setup in Local Physical Servers</title>
    <link href="/2023/04/30/devops/@2023_setup_kubernetes/"/>
    <url>/2023/04/30/devops/@2023_setup_kubernetes/</url>
    
    <content type="html"><![CDATA[<h1 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h1><p>在我自己在作为一名初学者学习编程的时候，曾看到过一位前辈在知乎日报中写道：</p><p>他们当年学习编程痛苦在根本找不到参考资料，只能自己硬着头皮摸索前进，不过好处是每个方向的技术选型基本上是固定的，不会有纠结；</p><p>而现在的初学者在一开始学习编程，就会很容易迷失在面对浩如烟海的技术路线选择中，尤其是热门的方向，总有前人做好了各种版本的教程、工具，完全不知道从哪里开始。</p><p>在我一开始学习DevOps的时候背过官方推荐的minikube教程， 到后来也尝试过搭建轻量化的k3s环境，算上业务中的阿里云容器服务Kubernetes版（Alibaba Cloud Container Service for Kubernetes，简称容器服务ACK），最终发现“搭建环境”本身也是造轮子的一部分，对提高<strong>理解应用能力</strong>甚微。</p><p>因此本文选择最简单的一种方式：<br><a href="https://kubesphere.io/zh/docs/v3.3/quick-start/all-in-one-on-linux/">在 Linux 上以 All-in-One 模式安装 KubeSphere</a>（以下简称<strong>官方文档</strong>），直接最简化地安装，然后再在使用中进行学习，毕竟<strong>背诵任何的学习资料都不如自己动手部署一遍</strong>。</p><span id="more"></span><h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>本文仅供学习使用，生产环境请使用云服务厂商提供的成熟的Kubernetes环境。</p><h1 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h1><p>Ubuntu 实体机 in roy-qtc6（有些时候master node的名字可能是这个），这是一台2013年刚上大学时候买的HASEE 神舟 精盾 K580S-i7D1，三千六就拿到当时平民级最强的CPU和显卡，甚至到10年后的今天不管是装Windows娱乐还是装Linux学习性能都充裕，对比一会儿提到的同龄人简直是扬我国威。</p><p>按照<a href="https://kubesphere.io/zh/docs/v3.3/quick-start/all-in-one-on-linux/">官方文档</a>中的步骤进行安装。</p><p>由于kubernetes与kubesphere之间存在一个版本匹配问题，因此我这里直接使用example中推荐的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ ./kk create cluster --with-kubernetes v1.22.12 --with-kubesphere v3.3.2<br></code></pre></td></tr></table></figure><p>当运行上述命令时，会检查机器是否安装依赖。</p><p>  在我这台机器上，只需要预先手动安装conntrack socat ebtables ethtool，其他组件会自动安装。</p><pre><code class="hljs">`$ apt-get install conntrack socat ebtables ethtool`</code></pre><table><thead><tr><th>name</th><th>sudo</th><th>curl</th><th>openssl</th><th>ebtables</th><th>socat</th><th>ipset</th><th>ipvsadm</th><th>conntrack</th><th>chrony</th><th>docker</th><th>containerd</th><th>nfs client</th><th>ceph client</th><th>glusterfs client</th></tr></thead><tbody><tr><td>master</td><td>y</td><td>y</td><td>y</td><td>y</td><td>y</td><td></td><td></td><td>y</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>查看log会发现 在依次安装kubelet、kubectl、helm、kubecni、crictl、etcd、docker等，在之后的教程里，会解释组件的作用。</p><p>经过漫长的等待之后，当console中出现Welcome hints、ip地址与默认admin账号密码， 就表示Kubenets安装完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ Welcome to KubeSphere!<br></code></pre></td></tr></table></figure><p>这个时候可以登录<a href="http://ip:30880/dashboard">http://ip:30880/dashboard</a> 进行可视化操作。</p><p>以上安装过程基本上是一键安装，在物理机器与Ubuntu系统没有太大问题的情况下，一小时之内能完成。</p><p>如果要安装官方的Kubernetes Dashboard的话，还需要手动安装、并配置外部访问与账号，这些额外的概念无疑会在一开始极大的增加初学者的负担。</p><p>而这些步骤&#x2F;组件 <strong>KubeSphere全家桶</strong>全都集成了，让开发者将更多的经历集中在理解与应用k8s核心组件与部署业务代码上。</p><p>接下来可以跟着官方文档应用学习其中组件了。</p><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><h3 id="WARNING-FileExisting-ethtool-ethtool-not-found-in-system-path"><a href="#WARNING-FileExisting-ethtool-ethtool-not-found-in-system-path" class="headerlink" title="[WARNING FileExisting-ethtool]: ethtool not found in system path"></a>[WARNING FileExisting-ethtool]: ethtool not found in system path</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ apt-get install ebtables ethtool<br></code></pre></td></tr></table></figure><p>这两个依赖是必须的，但是官方文档中没有列出来。</p><h3 id="kubectl-Please-wait-for-the-installation-to-complete"><a href="#kubectl-Please-wait-for-the-installation-to-complete" class="headerlink" title="kubectl Please wait for the installation to complete"></a>kubectl Please wait for the installation to complete</h3><p>安装的一直卡在这个命令，推测可能是kube-system中的k8s自己的pod没有就绪，另外启动一个shell查询pod状况；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl get pod -A<br>NAMESPACE           NAME                                           READY   STATUS    RESTARTS   AGE<br>...<br>kube-system         openebs-localpv-provisioner-57bbf864d5-zhl6k   0/1     Pending   0          26m<br>kubesphere-system   ks-installer-85d6fb8c97-mns4d                  0/1     Pending   0          26m<br></code></pre></td></tr></table></figure><p>查看其中一个pod的Events</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl describe pod openebs-localpv-provisioner-57bbf864d5-zhl6k -n kube-system<br>Name:           openebs-localpv-provisioner-57bbf864d5-zhl6k<br>...<br>Events:<br>  Type     Reason            Age                 From               Message<br>  ----     ------            ----                ----               -------<br>  Warning  FailedScheduling  97s (x35 over 36m)  default-scheduler  0/1 nodes are available: 1 node(s) had taint &#123;node-role.kubernetes.io/master: &#125;, that the pod didn<span class="hljs-string">&#x27;t tolerate.</span><br></code></pre></td></tr></table></figure><p>发现openebs-localpv-provisioner与ks-installer的STATUS均是Pending，通过Events里面的描述，发现是因为有taints所以pod调度不上去。</p><p>查看node的taints</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl get nodes -o json | jq <span class="hljs-string">&#x27;.items[].spec&#x27;</span><br>&#123;<br>  <span class="hljs-string">&quot;taints&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;effect&quot;</span>: <span class="hljs-string">&quot;NoSchedule&quot;</span>,<br>      <span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;node-role.kubernetes.io/master&quot;</span><br>    &#125;,<br>    &#123;<br>      <span class="hljs-string">&quot;effect&quot;</span>: <span class="hljs-string">&quot;NoSchedule&quot;</span>,<br>      <span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;node.kubernetes.io/not-ready&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><p>means that no pod can be scheduled on the master node unless it has a toleration for this taint123， 意思就是说不能在master节点上的和not-ready的pod不允许调度到我这个节点上。</p><p>The OpenEBS Local PV provisioner is designed to run on worker nodes and not on master nodes1. If you want to deploy the OpenEBS Local PV provisioner on a master node, you can do so by adding the label openebs.io&#x2F;engine&#x3D;provisioner to the master node2. However, it is not recommended to run the provisioner on master nodes as it can cause issues with the Kubernetes control plane</p><p>污点（Taint）是 Kubernetes 中的一个概念，它是一种标记，用于标识节点上的一些特殊条件，例如节点上的硬件故障或其他不可用性。 污点可以阻止 Pod 调度到具有特定污点的节点上。 有关更多信息，请参见<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">官方文档</a>。</p><p>Taints and Tolerations 是一起组合使用的，相当于“黑名单”机制，前者配置在nodes上，只能配置过后者的pod；</p><pre><code class="hljs">简单但是不推荐的做法： 将taints删除</code></pre><blockquote><p>:warning: <strong>不如直接用minikube单节点部署</strong>: 这里的意思是这个pod不能调度在master节点上，如果删了这个污点，相当于是强行调度在master上了。</p></blockquote><p>执行<code>kubectl taint nodes --all node-role.kubernetes.io/master-</code>, 这个命令是在将所有节点的node-role.kubernetes.io&#x2F;master 污点删除，以便可以在这些节点上调度非 master Pod。</p><p>然后发现唯一node上的taint没有了(这里换一个方法查看taints)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl describe node master | grep Taints<br>Taints:             &lt;none&gt;<br></code></pre></td></tr></table></figure><pre><code class="hljs">正规做法：先跳过这个pod的安装，参照下文先安装一个worker node并注册到cluster，然后再重复安装步骤安装。</code></pre><p>完成安装worker node并注册到cluster后，验证查看当前nodes</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl get nodes<br>NAME             STATUS   ROLES                  AGE    VERSION<br>worker           Ready    worker                 9h     v1.22.12<br>master           Ready    control-plane,master   4d3h   v1.22.12<br></code></pre></td></tr></table></figure><p>当看到出现STATUS为Ready的worker时候，就可以再执行<code>./kk create cluster --with-kubernetes v1.22.12 --with-kubesphere v3.3.2</code>，然后经过漫长的等待即可。</p><h1 id="Worker-Node"><a href="#Worker-Node" class="headerlink" title="Worker Node"></a>Worker Node</h1><p>Ubuntu 实体机 in roy-macbookair（有些时候worker node的名字可能是这个），这是一台2013款的具有10年历史的老机器，陪我拿到了第一家上市公司的offer，但目前已经无法正常运行macOS，因此安装Ubuntu（图形化模式略微卡顿，使用命令行模式才能流畅运行k8s）。</p><p>按照<a href="https://kubesphere.io/zh/docs/v3.3/installing-on-linux/introduction/multioverview/">在 Linux 上多节点安装</a>中的步骤进行安装。</p><p>将一台新准备好的Linux物理机， 作为Node（不管Worker是Master）添加到cluster只需要KubeKey + SSH 就能完成。</p><p>那么同样地，先安装相关地依赖<br><code>$ apt install conntrack socat ebtables ethtool</code></p><p>然后在当前目录下创建一个config-sample.yaml的文件（这一步可以在新机器的终端上完成，也可也在已有集群的任意一个物理机的终端上完成）<br><code>$ ./kk create config</code></p><p>在我这里，config-sample.yaml的内容如下，其中的ssh相关的信息需要自己填写，这里我使用的是密码登录，因此需要填写密码，如果使用的是ssh key登录，则不需要填写密码（但是需要配置ssh-key）。</p><p>然后按照教程中的配置文件，结合自己的node name与ip，修改配置文件，然后执行<code>$ ./kk create cluster -f config-sample.yaml</code>（集群未安装）&#x2F; <code>/kk add nodes -f sample.yaml</code>（集群已安装），等待一段时间后，集群就安装好了。</p><p>在经过以上操作后，可以看到我成功的创建了一个一共拥有3个Node的Cluster，就可以开始自己的kubenets操作了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">13:09:53 CST success: [roy-qtc6]<br>13:09:53 CST success: [roy-300]<br>13:09:53 CST success: [roy-macbookair]<br>13:09:53 CST Pipeline[AddNodesPipeline] execute successfully<br>❯ kubectl get nodes<br>NAME             STATUS   ROLES                  AGE     VERSION<br>roy-300          Ready    worker                 2m41s   v1.22.12<br>roy-macbookair   Ready    worker                 23h     v1.22.12<br>roy-qtc6         Ready    control-plane,master   4d18h   v1.22.12<br></code></pre></td></tr></table></figure><p>安装出了问题也别急，<code>./kk delete cluster</code>解君愁。</p><h1 id="角色、权限等配置"><a href="#角色、权限等配置" class="headerlink" title="角色、权限等配置"></a>角色、权限等配置</h1><p>就像大多数成熟的管理系统一样，初始化安装之后会分配一个admin账户，然后再通过该账户创建一个业务账户，之后大多数操作都应该通过业务账户进行操作。</p><p>而这些概念、操作在每个云平台上略有不同，且不影响k8s的核心组件，同时又都是基本都能在Web UI进行点点点操作，所以本段略。</p><p>可以参考<a href="https://kubesphere.io/zh/docs/v3.3/quick-start/create-workspace-and-project/">在kubesphere创建企业空间、项目、用户和平台角色</a></p><h1 id="外部访问"><a href="#外部访问" class="headerlink" title="外部访问"></a>外部访问</h1><p>在安装好Cluster之后，可以看到每个Node连接的IP地址是10开头的，这个明显是Kubernetes Cluster的IP地址， 不是外部可以访问的IP地址，因此需要一个网关来提供外部访问。</p><h2 id="启动网关"><a href="#启动网关" class="headerlink" title="启动网关"></a>启动网关</h2><p>网关是在项目中运行的 <a href="https://github.com/kubernetes/ingress-nginx">NGINX Ingress 控制器</a>。</p><p><a href="https://www.kubesphere.io/zh/docs/v3.3/pluggable-components/service-mesh/">在安装后启用服务网格</a></p><pre><code class="hljs">本段为KubeSphere的配置，其他云平台可能不同</code></pre><p>使用定制资源定义（CRD）里面的clusterconfiguration的ks-installer进行安装，看名字就知道是KubeSphere自己的，其他云平台没有。</p><h2 id="提供外部访问"><a href="#提供外部访问" class="headerlink" title="提供外部访问"></a>提供外部访问</h2><p><a href="https://www.kubesphere.io/zh/docs/v3.3/cluster-administration/cluster-settings/cluster-gateway/">设置集群网关</a><br>访问模式设置为 NodePort，选择确定之后，集群网关详情里面会出现一个和宿主机网段相同的局域网网关IP地址（在我这里是192开头的），这个是可以访问的。</p><p><a href="https://www.kubesphere.io/zh/docs/v3.3/multicluster-management/enable-multicluster/retrieve-kubeconfig/#%E8%8E%B7%E5%8F%96-kubeconfig">通过使用 kubeconfig 文件配置访问集群</a><br>除了上面链接中的方法外，还可以在KubeSphere UI右下角的工具箱图标上悬停，然后在弹出菜单中选择 kubeconfig，点击右上角的下载按钮，就可以直接下载连接K8s的kubeconfig.yaml。</p><p>特别注意的是需要把Cluster里面的server IP替换为局域网的IP</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">clusters:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">cluster:</span><br>    <span class="hljs-attr">server:</span> <span class="hljs-string">https://10.233.0.1:443</span>  <span class="hljs-comment"># 替换为集群网关详情里面和宿主机网段相同的局域网网关IP地址</span><br></code></pre></td></tr></table></figure><h1 id="KubeSphere-DevOps-系统"><a href="#KubeSphere-DevOps-系统" class="headerlink" title="KubeSphere DevOps 系统"></a>KubeSphere DevOps 系统</h1><pre><code class="hljs">本段为KubeSphere的配置，其他云平台可能不同，步骤在[KubeSphere DevOps 系统](https://kubesphere.io/zh/docs/v3.3/pluggable-components/devops/)</code></pre><p>KubeSphere全家桶的DevOps 系统基于 Jenkins 的 KubeSphere DevOps 系统是专为 Kubernetes 中的 CI&#x2F;CD 工作流设计的，它提供了一站式的解决方案，帮助开发和运维团队用非常简单的方式构建、测试和发布应用到 Kubernetes。(得了，感觉以前的工作又是造轮子了，这叫深度业务定制开发！)</p><blockquote><p>:warning: <strong>整个集群内存最好25Gi以上</strong>: 我一开始安装的时候就遇到了各种卡住且没有提示的问题，其实就是内存不够，但是增加内存是需要硬件成本的，排查的时候花了很多的精力和时间。</p></blockquote><h2 id="Troubleshooting-1"><a href="#Troubleshooting-1" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><p>在之前工作中用过实体机上的Jenkins，也用过k8s节点中的Jenkins，但从来没用过全家桶的Jenkins，因此本段就算安装不上，也完全不影响使用。</p><h3 id="安装一直卡住，没有任何提示与报错"><a href="#安装一直卡住，没有任何提示与报错" class="headerlink" title="安装一直卡住，没有任何提示与报错"></a>安装一直卡住，没有任何提示与报错</h3><p>很自然去查看pod状况。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl get pod -n kubesphere-devops-system<br>devops-jenkins-c8b495c5-4hqwf        0/1     Pending     0          19h<br><br>❯ kubectl describe pod devops-jenkins-c8b495c5-4hqwf -n kubesphere-devops-system<br>...<br>Containers:<br>  devops-jenkins:<br>...<br>    Requests:<br>      cpu:      2<br>      memory:   2Gi<br>Events:<br>  Type     Reason            Age    From               Message<br>  ----     ------            ----   ----               -------<br>  Warning  FailedScheduling  69m    default-scheduler  0/1 nodes are available: 1 node(s) had taint &#123;node.kubernetes.io/memory-pressure: &#125;, that the pod didn<span class="hljs-string">&#x27;t tolerate.</span><br></code></pre></td></tr></table></figure><p>（这里有时Events里面会是空的，就只能靠其他信息推测了）</p><p>但是很神奇的是查看node本身并没有添加任何污点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">❯ kubectl get nodes -o json | jq <span class="hljs-string">&#x27;.items[].spec.taints&#x27;</span><br>null<br></code></pre></td></tr></table></figure><p>然后再仔细审视<code>describe pod devops-jenkins</code>pod的描述，报错是内存pressure，多半是内存不足，然后惊讶地发现需要2Gi的内存，而我的传家宝MacBook Air只剩下可怜的不到1Gi，由于这是物理资源的不足，无法弥补，要么放弃体验KubeSphere DevOps全家桶，要么只能自己在另一台物理机&#x2F;node上安装jenkins。</p><p>一想到某人那种32Gi的电脑沉迷召唤师峡谷，就想悄悄给装一个Ubuntu上去996.</p><p>（2天后更新： 结果把自己的神船刷Ubuntu了，然后去给朋友搬家捡了的PC）</p><p>整一些内存大的电脑添加到Cluster 成为Node就好了。</p><p>实测发现要装KubeSphere DevOps 系统最好还是保证整个集群内存有25Gi以上的容量，否则会出现各种问题，为此时隔十多年我又玩起了虚拟机，这里<strong>只推荐正统的VMware，VirtualBox</strong>这种，否则虚拟化的大坑欢迎您。</p><h1 id="Cluster-Uninstall"><a href="#Cluster-Uninstall" class="headerlink" title="Cluster Uninstall"></a>Cluster Uninstall</h1><p>当Cluster出现某些问题，且安装上面的排查依旧不能解决的时候，就使用重装大法，DevOps的其中一个特质就是无状态、重装方便，在应用部署上这是巨大的进步。</p><p>首先需要一个config-sample.yaml来配置集群的信息，比如Master &#x2F; Worker Node 的IP，账户等，如果没有的话，<code>./kk create config-sample.yaml</code>生成一下新的。</p><p>然后<code>./kk delete cluster -f config-sample.yaml</code></p><p>接着SSH到每一台Worker Node机器上，进行<a href="https://stackoverflow.com/questions/44698283/how-to-completely-uninstall-kubernetes">深度清理</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubeadm reset<br><span class="hljs-built_in">sudo</span> apt-get purge kubeadm kubectl kubelet kubernetes-cni kube*   <br><span class="hljs-built_in">sudo</span> apt-get autoremove  <br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf ~/.kube<br></code></pre></td></tr></table></figure><p>上面这个命令是把包都干掉了（而且实测不用重启机器就生效）</p><p>If you are clearing the cluster so that you can start again, then, in addition do the following to ensure my systems are in a state ready for kubeadm init again:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubeadm reset -f<br><span class="hljs-built_in">rm</span> -rf /etc/cni /etc/kubernetes /var/lib/dockershim /var/lib/etcd /var/lib/kubelet /var/run/kubernetes ~/.kube/*<br>iptables -F &amp;&amp; iptables -X<br>iptables -t nat -F &amp;&amp; iptables -t nat -X<br>iptables -t raw -F &amp;&amp; iptables -t raw -X<br>iptables -t mangle -F &amp;&amp; iptables -t mangle -X<br>systemctl restart docker<br></code></pre></td></tr></table></figure><p>这个时候就算清理干净了，最后再回到Master Node机器上，执行<code>./kk create cluster -f config-sample.yaml</code>，等待一段时间后，集群就重新安装好了。</p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>本文历时半个月，从4月13号被干掉，休息半个月，5月1号开始搭环境，经过了半个月走走停停，不断地试错，查资料，写总结，才终于在5月20号地今天完成这个学习计划的开头 ————环境搭建。</p><p>这一个月里，有耍到接近昏迷，也有一天4个场面试的高强度，有点回到了快毕业那会的节奏。只是再也不像当初那么无助，迷茫而又没用行动力了。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Setup</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从二叉树遍历到yield，然后到协程、异步</title>
    <link href="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/"/>
    <url>/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/</url>
    
    <content type="html"><![CDATA[<p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield01.png" alt="本图由 2025年11月20日 谷歌发布的Nano Banana Pro （Gemini 3 Pro图像）生成"></p><blockquote><p>用最新的模型生成很老的知识点，一种又新又旧的学习体验。</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这是一篇跨越 3年 又新又旧的文章。<br>（或者说单纯鸽了这么久，上次写作的细节仍历历在目）</p><p>当时写作时 ChatGPT 都没落地，为了调一个 Blog 展示效果还得花上许多时间查文档，试实现。</p><p>现在 AI 的存在已经让手写 Blog 这种类似以前游戏中为了节省算力资源预先渲染好的的 “过场动画” 大部分时候没什么意义了，想要查询什么知识点的时候，直接实时生成一篇 Post，通识知识质量还高于绝大多数。</p><p>看了一下时间，正好是来上海的第一份工作，封控将要结束，从共享办公室搬到自己租的办公楼时候。</p><span id="more"></span><p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/background.png" alt="写作背景"></p><blockquote><p>这张生成图真的太抽象了，而且我说了我是 2025年3月去的百度，不知道 2023 和 “虚桌” 是什么意思。。。</p></blockquote><p>那个时候刚刚才接触云服务，又正值 AI 普及方兴未艾，面对公司都是谷歌退下来的老人，没想到自己两年后也会去百度走一遭。</p><p>一晃也真的是又 3年 过去了，再不抓紧总结点什么的话，感觉都留不下自己的痕迹。</p><p>本文理论部分大规模参考以下视频，甚至可以当成是学习读书笔记。当视频看到第4遍，同时再加上不断地应用 ayscio 相关的架构，总算把这个抽象的概念越看越具体了。</p><iframe src="//player.bilibili.com/player.html?isOutside=true&aid=726448831&bvid=BV1sS4y1b7qb&cid=718057385&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="width: 100%; height: 500px;"> </iframe><h1 id="yield-是什么"><a href="#yield-是什么" class="headerlink" title="yield 是什么"></a>yield 是什么</h1><blockquote><p> yield的作用<br>首先yield就是return，不要想多了，所以搭配<code>yield from func()</code>能够递归，就是这么简单；</p><p>只是说普通的函数返回的是一个value或者obj，而yield返回的是一个生成器对象。<br> 生成器的定义&amp;同迭代器的区别<br>在python中实现了__iter__和__next__方法，可以迭代操作的对象就叫迭代器；<br>构建迭代器的时候，并不一次性加载所有元素到内存，只有调用next方法的时候才会<strong>返回</strong>需要的该元素；<br>生成器就是一种迭代器，由生成器函数返回；<br>生成器函数就是上文中的 return -&gt; yield的函数；  </p></blockquote><p>我当年的说法本身没什么问题，但是太过流于表面，从性质进行总结，而不是真正看它怎么实现的。</p><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>当前我并没有阅读 Python 源码的计划，因此仅在豆包的指导下，涉猎 Objects&#x2F;genobject.c 等文件，理解了调用栈等相关概念的实现部分。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>要想真正知道 yield 是什么，一定要先应用，再来看概念，而不是像传统9年义务教育那样反其道而行之，此处略去应用的部分。</p><p>在一定的使用积累之后，我们对这个这个概念的感觉就没有那么抽象了。这个时候再查阅 Python 官方文档 <a href="https://docs.python.org/3/reference/expressions.html#yield-expressions">https://docs.python.org/3/reference/expressions.html#yield-expressions</a></p><div class="note note-info">            <p>expression： 就像正则表达式，会有返回值的那种。</p><p>statement： 就像 print 语句，不会有返回值。</p><p>这里顺便提一个一个我一直搞混淆的概念 <strong>生成器表达式</strong>，会返回一个生成器。</p><blockquote><p>在以前，我一直把 “列表生成式” 读做了 “列表生成器”，与本处讨论的 “生成器” 产生了不应当的混淆，对我早期学习、与面试造成了巨大的困难。</p></blockquote><p>为了行文统一，我们可以像列表生成式那样，用生成器生成式来称呼它，</p>          </div><p>在文档中提到，当一个正常的 function &#x2F; method 中只要出现了 yield 表达式，它就不再是一个平凡的 function &#x2F; method， 而是一个生成器了。</p><p>在这里引入了生成器这个新概念，因此我们先用一点专门的篇幅去讨论。</p><h1 id="迭代器是什么"><a href="#迭代器是什么" class="headerlink" title="迭代器是什么"></a>迭代器是什么</h1><p>生成器是一种迭代器，那么自然地又要先入栈一个新概念。</p><h2 id="迭代是什么"><a href="#迭代是什么" class="headerlink" title="迭代是什么"></a>迭代是什么</h2><p>更加自然地，我们再次入栈一个新概念： 迭代，和可迭代对象</p><h3 id="迭代是什么-1"><a href="#迭代是什么-1" class="headerlink" title="迭代是什么"></a>迭代是什么</h3><p>首先迭代可以是一个数学的定义，就类似于高中学习的 “递推公式” 中的这种项于项之间的关系。</p><p>迭代（英语：iteration），亦作疊代，是重复反馈过程的活动，其目的通常是为了接近并且到达所需的目标或结果。每一次对过程的重复被称为一次“迭代”，而每一次迭代得到的结果会被用来作为下一次迭代的初始值。</p><h3 id="可迭代对象是什么"><a href="#可迭代对象是什么" class="headerlink" title="可迭代对象是什么"></a>可迭代对象是什么</h3><p>具体的来说，在 Python 里面，可以跟在 in 关键字后面的就是 <strong>可迭代对象</strong>。</p><p>抽象的来说，可迭代对象（Iterable）： 能够被迭代（遍历）的对象，作为 “数据容器”，提供迭代的 “数据来源”，但不负责迭代的具体逻辑（如 “如何获取下一个元素”“是否迭代结束”）</p><p>按照视频中的拆解 Python 实现后发现，实现了 <code>__iter__ </code> 方法，用来随时返回容器里面的数据的对象，就叫做可迭代对象。而且也满足上述定义：能返回自身作为被迭代的对象，且不需要知道对象之间（如何迭代）关系。</p><h2 id="迭代器是什么-1"><a href="#迭代器是什么-1" class="headerlink" title="迭代器是什么"></a>迭代器是什么</h2><p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield02.jpg" alt="可迭代对象和迭代器的区别"></p><blockquote><p>很明显的能够看到，由于可迭代对象（Iterable）只是 “数据容器”，且不知道迭代逻辑，因此不具备 “惰性计算” 的能力，还是一股脑加载到内存里面的。</p></blockquote><p>在可迭代对象的基础上，再实现 <code>__next__ </code> 方法，体现出对象之间（如何迭代）关系，就得到了迭代器。</p><p>具体的来说：迭代器（Iterator）： 实现了迭代协议（Iterator Protocol）的对象，是 “迭代的具体执行者”—— 负责按顺序生成下一个元素、记录迭代状态、判断迭代结束。</p><p>正如同常见的 递推公式 需要知道 自己 和 之后其他项 之间（如何迭代）关系，因此迭代器 除了也有 <code>__iter__ </code> 方法返回它自身以外， 还有 <code>__next__ </code> 方法返回之后（如何迭代）关系的 “其他项”。</p><blockquote><p>最贴合迭代概念的数据结构就是链表，可以通过 head指针 指向自己，再通过 self.next 属性指向下一个被迭代的项。</p></blockquote><p>我们现在讲完了迭代器这个还算能有具体数据结构能对应的概念，但是我们先不急着扩展到生成器，先按照文章开头说的，应用一下。</p><h1 id="yield-怎么应用"><a href="#yield-怎么应用" class="headerlink" title="yield 怎么应用"></a>yield 怎么应用</h1><p>同样我们先从我们最熟悉的普通函数入手，看看我们能怎么实现迭代这个动作。</p><h2 id="手动实现迭代这个动作概念"><a href="#手动实现迭代这个动作概念" class="headerlink" title="手动实现迭代这个动作概念"></a>手动实现迭代这个动作概念</h2><p>在这里我们设定一个最简单的目标： 在不借助额外数据结构的帮助下，如何迭代地输出 1, 2, 3。</p><blockquote><p>迭代地输出，意味着我们要运行3次这个函数，并且每次依次返回 1, 2, 3，一次性返回肯定是不可以的。 </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>():  <span class="hljs-comment"># 普通函数</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">3</span><br><br><span class="hljs-built_in">print</span>(func())<br><span class="hljs-built_in">print</span>(func())<br><span class="hljs-built_in">print</span>(func())<br></code></pre></td></tr></table></figure><p>很自然地，我们发现 return 之后的代码不会执行，因此我们只能引入分支实现输出不同的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>():  <span class="hljs-comment"># 普通函数 + 分支</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">3</span><br><br><span class="hljs-built_in">print</span>(func())<br><span class="hljs-built_in">print</span>(func())<br><span class="hljs-built_in">print</span>(func())<br></code></pre></td></tr></table></figure><p>想法很自然，报错的时候就发现，我们并没有定义这个用来计数的 exection_count。</p><p>最简单的做法就是把 exection_count 设计成一个全局变量，并且每次执行就增加一次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">exection_count = <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>():  <span class="hljs-comment"># 普通函数 + 分支 + 全局变量（用来计数）</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">if</span> exection_count == <span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">3</span><br><br><span class="hljs-built_in">print</span>(func())<br>exection_count += <span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(func())<br>exection_count += <span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(func())<br></code></pre></td></tr></table></figure><blockquote><p>当然这样实现的代码 func 很不独立，也有把这个 exection_count 放到 func 里面并自动 +1 的办法，这里不展开，对本文来说没有区别。</p></blockquote><h2 id="用-yield-实现迭代这个动作概念"><a href="#用-yield-实现迭代这个动作概念" class="headerlink" title="用 yield 实现迭代这个动作概念"></a>用 yield 实现迭代这个动作概念</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen</span>():  <span class="hljs-comment"># 生成器函数</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">3</span><br><br>it = gen()<br><span class="hljs-built_in">print</span>(it)  <span class="hljs-comment"># &lt;generator object gen at 0x1066d0a90&gt;</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))  <span class="hljs-comment"># 1</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))  <span class="hljs-comment"># 2</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))  <span class="hljs-comment"># 3</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))  <span class="hljs-comment"># StopIteration</span><br></code></pre></td></tr></table></figure><p>还记得链表吗，在不追求严谨，仅为了形象的情况下，现在假设我们有一个最典型的 空值节点 作为表头的一个链表， 这个空值节点，也就是头节点，就是这里单纯为了标记整个生成器起点的 <code>it = gen()</code>，然后我们需要依次遍历整个链表，就需要移动沿着链表的<strong>迭代关系</strong>移动指针看，也是同样用的 <code>next</code>。</p><p>最后链表的尾节点的 next 指向了一个 None，再对 None.next 就会报错。</p><div class="note note-warning">            <p>这里就没必要贴图了，假如对链表都不熟悉，那就应该去刷题，而不是再看 yield 这个概念。</p>          </div><p>同样的，优雅地遍历生成器很自然地就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen</span>():  <span class="hljs-comment"># 生成器函数</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">yield</span> <span class="hljs-number">3</span><br><br>it = gen()<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))<br>    <span class="hljs-keyword">except</span> StopIteration:<br>        sys.exit()<br></code></pre></td></tr></table></figure><h1 id="yield-与树的遍历-写本文的契机"><a href="#yield-与树的遍历-写本文的契机" class="headerlink" title="yield 与树的遍历 - 写本文的契机"></a>yield 与树的遍历 - 写本文的契机</h1><h2 id="中序遍历一个BST"><a href="#中序遍历一个BST" class="headerlink" title="中序遍历一个BST"></a>中序遍历一个BST</h2><p>BST 是 二叉搜索树（Binary Search Tree）的缩写，也称为二叉查找树或二叉排序树。它的核心特性是：任何一个节点的左子树中所有节点的值都小于该节点的值，而右子树中所有节点的值都大于该节点的值；并且它的左、右子树本身也都是二叉搜索树。</p><p>其实这里用二叉树就可以了，但 leetcode 上用的 BST，就原封不动抄过来了。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>说起来这也是我刚毕业的时候面试微软的第一道题一个类型。</p><p>当访问完了一个结点准备访问它子节点的时候，很自然的接着访问 .left 或者 .right 就行。</p><p>但是这时把 visit 指针挪开了，自己当前的位置就丢掉了，比如我现在访问 .left ，等访问结束的时候，我如何才能继续访问 .right呢？</p><p>很自然的，我们需要一个清单来维护先后访问节点的顺序，不至于一旦开始访问，就丢掉了现在的位置。</p><h2 id="使用普通函数实现-（栈）"><a href="#使用普通函数实现-（栈）" class="headerlink" title="使用普通函数实现 （栈）"></a>使用普通函数实现 （栈）</h2><p>首先有个大原则，就是选择好访问辅助 “清单” 的数据结构，当时面试微软时，我就是没有第一时间想起，浪费时间搞了心态。</p><p>其次我们都知道在《数据结构》这门课里面会学到遍历一个数据结构的时候，有 深度优先(DFS) 和 广度优先(BFS) 两种方式，如果不清楚可以先 上课 + 刷题。</p><p>然后很科学的是，先人设计出了 <strong>FIFO(先进先出)的队列</strong>，可以遍历的时候先放入当前节点，然后依次放入子节点（暂时不访问），进入子节点之前，再统一访问队列中的节点，这样就把本来树中不能直接体现的层级关系体现了出来；</p><p>同时还设计出了 <strong>LIFO(后进先出)的栈</strong>，专门用于深度优先遍历。栈的核心思想是”<strong>后进先出</strong>“：最后放入栈的元素最先被访问，这让栈天然适合实现深度优先的访问模式。</p><p>最后和本文 栈 和本文主题关系密切，必须单独一个章节描述。</p><h3 id="为什么栈能够实现深度优先遍历？"><a href="#为什么栈能够实现深度优先遍历？" class="headerlink" title="为什么栈能够实现深度优先遍历？"></a>为什么栈能够实现深度优先遍历？</h3><p>栈的LIFO特性决定了访问顺序：<strong>优先处理最近遇到的节点</strong>。这种特性天然地实现了”<strong>深度优先</strong>“的遍历策略——总是沿着当前路径走到最深，再回退处理其他分支。</p><p>举个例子，对于树结构 <code>A -&gt; (B, C)</code>，<code>B -&gt; (D, E)</code>：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">    <span class="hljs-variable">A</span><br>   <span class="hljs-operator">/</span> \<br>  <span class="hljs-variable">B</span>   <span class="hljs-built_in">C</span><br> <span class="hljs-operator">/</span> \<br><span class="hljs-built_in">D</span>   <span class="hljs-built_in">E</span><br></code></pre></td></tr></table></figure><p><strong>栈的工作过程</strong>：</p><ul><li>先将根节点A入栈</li><li>弹出A，访问A，并将A的子节点按<strong>右左顺序</strong>入栈：先C后B（这样B会在C之前被访问）</li><li>弹出B，访问B，并将B的子节点按<strong>右左顺序</strong>入栈：先E后D</li><li>弹出E，访问E（E是叶子节点，无子节点可入栈）</li><li>弹出D，访问D（D是叶子节点，无子节点可入栈）</li><li>弹出C，访问C（C是叶子节点，无子节点可入栈）</li></ul><p>最终访问顺序：<strong>A → B → D → E → C</strong>，完美实现了深度优先遍历。</p><h3 id="队列-vs-栈的本质区别"><a href="#队列-vs-栈的本质区别" class="headerlink" title="队列 vs 栈的本质区别"></a>队列 vs 栈的本质区别</h3><ul><li><strong>队列(FIFO)</strong>：保证<strong>层级顺序</strong>，先遇到的节点先处理子节点，实现广度优先</li><li><strong>栈(LIFO)</strong>：保证<strong>深度优先</strong>，后遇到的节点先被处理，优先探索深度方向</li></ul><p>总结一下：<br>队列 vs 栈 都是辅助我们记住当前遍历属性的 “清单”， 发生在我们访问到当前节点，将要进入下一个节点之前。</p><p>现在让我们看看具体的栈实现： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TreeNode</span>(<span class="hljs-title class_ inherited__">object</span>):  <span class="hljs-comment"># 定义一个二叉树</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val=<span class="hljs-number">0</span>, left=<span class="hljs-literal">None</span>, right=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-variable language_">self</span>.val = val<br>        <span class="hljs-variable language_">self</span>.left = left<br>        <span class="hljs-variable language_">self</span>.right = right<br><br>value_list = [random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br><span class="hljs-built_in">print</span>(value_list)<br><br>node = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.left = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.right = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.left.left = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.left.right = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.right.left = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br>node.right.right = TreeNode(value_list.pop(<span class="hljs-number">0</span>))<br><br>result = []<br>stack = []<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">in_order_visit</span>(<span class="hljs-params">node: TreeNode</span>):<br>    <span class="hljs-comment"># 从根节点开始，一直往左走，将路径上的节点都压入栈</span><br>    current = node<br>    <span class="hljs-keyword">while</span> current <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> stack:<br>        <span class="hljs-comment"># 先遍历左子树，将所有左节点压入栈</span><br>        <span class="hljs-keyword">while</span> current <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            stack.append(current)<br>            current = current.left<br><br>        <span class="hljs-comment"># 弹出栈顶节点（最左边的节点）</span><br>        current = stack.pop()<br>        result.append(current.val)<br><br>        <span class="hljs-comment"># 转向右子树</span><br>        current = current.right<br><br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-comment"># 测试中序遍历</span><br>result = in_order_visit(node)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;中序遍历结果:&quot;</span>, result)<br><br><span class="hljs-comment"># 验证结果是否正确 - 中序遍历应该得到升序排列（如果树是BST的话）</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;排序验证:&quot;</span>, <span class="hljs-built_in">sorted</span>([n.val <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> [node, node.left, node.right, node.left.left, node.left.right, node.right.left, node.right.right]]))<br><br><span class="hljs-comment"># 打印树结构</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_tree</span>(<span class="hljs-params">node, level=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-keyword">if</span> node:<br>        print_tree(node.right, level + <span class="hljs-number">1</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27; &#x27;</span> * <span class="hljs-number">4</span> * level + <span class="hljs-string">&#x27;-&gt;&#x27;</span>, node.val)<br>        print_tree(node.left, level + <span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n树结构:&quot;</span>)<br>print_tree(node)<br></code></pre></td></tr></table></figure><p>我这里写完了才发现是普通二叉树，而不是搜索的，鉴于题中给定的是构造好的树，且在本文中没有区别，就不管了。</p><h2 id="使用递归实现"><a href="#使用递归实现" class="headerlink" title="使用递归实现"></a>使用递归实现</h2><p>递归的思想这里不展开了，请咨询查阅《数据结构》，这里想表述的是，递归会自动维护一个栈，当在函数中调用自身的时候，会将当前的变量和状态都封存到这个栈的一个帧中，因此不需要手动维护 stack &#x3D; [] 这个全局变量了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">in_order_visit</span>(<span class="hljs-params">node: TreeNode</span>):<br>    <span class="hljs-keyword">if</span> node == <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 递归基</span><br>        <span class="hljs-keyword">return</span><br><br>    <span class="hljs-comment"># 按照中序遍历的</span><br>    in_order_visit(node.left)  <span class="hljs-comment"># 如果有左子树，则先访问左子树</span><br>    <span class="hljs-built_in">print</span>(node.val)  <span class="hljs-comment"># 走到这里说明访问过左子树了，现在要访问当前节点</span><br>    in_order_visit(node.right)  <span class="hljs-comment"># 最后访问右子树</span><br><br>in_order_visit(node)<br></code></pre></td></tr></table></figure><p>优雅，无需多言。 而且甚至还高度抽象，非常直观地符合中序遍历的定义。</p><h2 id="生成器实现"><a href="#生成器实现" class="headerlink" title="生成器实现"></a>生成器实现</h2><p>既然递归可以自行维护一个栈，那么我们是不是还可以更进一步，再抽象一个高度，解放双手呢？</p><p>是的可以的。</p><p>前文已经说过使用 yield 之后，原来的函数就成为一个生成器，能够使用的时候再把栈帧加载到内存</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">in_order_visit_gen</span>(<span class="hljs-params">node: TreeNode</span>):<br>    <span class="hljs-keyword">if</span> node <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># 有错的版本</span><br>    <span class="hljs-keyword">yield</span> visit_bst(node.left)<br>    <span class="hljs-keyword">yield</span> node.val<br>    <span class="hljs-keyword">yield</span> visit_bst(node.right)<br><br><br>it = in_order_visit_gen(node)<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))<br>    <span class="hljs-keyword">except</span> StopIteration:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p>当我们运行的时候，惊讶的发现，并没有像刚刚那样，直接优雅的递归进去，而是仅仅返回了生成器（不接着递归了）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">&lt;generator object in_order_visit_gen at 0x1083ff940&gt;<br>26<br>&lt;generator object in_order_visit_gen at 0x1083ff940&gt;<br></code></pre></td></tr></table></figure><p>简单来说，想要递归一个生成器的时候，要额外使用 yield from 关键字， 优雅的提供了判断， 如果还能 next() 则递归进去， 如果到底了，则自动处理 StopIteration。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">in_order_visit_gen</span>(<span class="hljs-params">node: TreeNode</span>):  <span class="hljs-comment"># 最终版本，优雅，简洁</span><br>    <span class="hljs-keyword">if</span> node <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">yield</span> <span class="hljs-keyword">from</span> in_order_visit_gen(node.left)<br>    <span class="hljs-keyword">yield</span> node.val<br>    <span class="hljs-keyword">yield</span> <span class="hljs-keyword">from</span> in_order_visit_gen(node.right)<br><br><br>it = in_order_visit_gen(node)<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(it))<br>    <span class="hljs-keyword">except</span> StopIteration:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p>最终版本连递归都不需要我们维护，正如递归会自动维护一个栈一样，递归一个生成器的时候它会自动维护相关上下文，又向上屏蔽了一些细节。</p><h1 id="由-yield-from-走向协程"><a href="#由-yield-from-走向协程" class="headerlink" title="由 yield from 走向协程"></a>由 yield from 走向协程</h1><p>yield from 额外还有 双向通信 的特点，本文知识点已经够多了，这里就先省略。</p><h2 id="生成器和迭代器的区别"><a href="#生成器和迭代器的区别" class="headerlink" title="生成器和迭代器的区别"></a>生成器和迭代器的区别</h2><p>话说这是之前遇到很高频的面试问题了，以前并没有系统的学习过，也只是从用法上进行了一些回答，回想起来不甚满意。</p><p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield03.png" alt="迭代器和生成器的区别"></p><p>总的来说，正如之前 yield 相关的代码展示的那样， yield 自动维护了相关的计数，手动维护全局变量。</p><p>在屏蔽底层 C语言 实现的细节下，我认为我们已经阐述清楚了 <strong>迭代器</strong> 这个概念，接下来我们继续讨论生成器。</p><p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield04.png" alt="迭代器和生成器的区别-底层实现"></p><p>我们往底层实现来看，发现 迭代器 是很自然用了共享的 “清单” 变量，每次操作的时候，都需要维护这个 “清单” 变量，而生成器会自动的利用封存的 栈帧 来维持这个状态。</p><p><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield05.png" alt="生成器有栈帧"><br>这张图是刚开始使用，没有按照 文生图 提示词规则，而是直接使用自然语言描述得到的版本，宝贵的是能明显凸显出当生成器调用 .next() 的时候，会保存栈帧这个动作，因此这张图还是保留了下来。</p><h2 id="多进程、多线程、协程的区别"><a href="#多进程、多线程、协程的区别" class="headerlink" title="多进程、多线程、协程的区别"></a>多进程、多线程、协程的区别</h2><p>在我刚接触编程的时候，我就尝试用生活化的例子构建场景进行学习，现在终于可以轻松实现了。<br><img src="/2022/05/29/book/@2022_python_grammer_yield%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/yield06.png" alt="区别"></p><p>根本定义： </p><ol><li>进程是 资源分配 的最小单位；</li><li>线程是 CPU执行 的最小单位；</li><li>异步是具有 主动释放CPU执行 能力的执行程序（与上两者完全不是一个层面的概念）。</li></ol><p>进程:</p><ol><li>具有真正并行的能力（需要硬件 + 操作系统支持）；</li><li>正所谓 “并行计算”， 是真正能同时计算执行的；</li></ol><p>线程：</p><ol><li>“并发执行”，需要疯狂切上下文，实际上一个单位时间只能有一个线程在执行；</li><li>多线程本身并不能增加执行能力，除非当前有多个核心 + 语言的多线程支持多核心调用；</li><li>续：Python 3.14 前的 CPython解释器的 GIL 就是在 进程级 加上了 全局互斥锁， 因此一个同一时刻只能有一个线程能够被执行，就算有多个核心，也只有一把锁。多线程本身和多进程概念并不互斥。</li></ol><p>异步：</p><ol><li>需要代码本身有释放能力，也就是通过上文的生成器实现；</li><li>需要修改之前的代码，也就是出现经典的面试题： 如果异步代码中出现了同步的代码会怎么样-会占用整个进程导致其他的协程卡死；</li><li>await 高度借鉴了 yield from，通过 事件循环 监控区分后面接的 <strong>可等待对象（Awaitable）</strong> 是否完成</li><li>续：还没完成-就像上文中的递归，返回自己然后继续等待；完成-协程抛出 StopIteration 表示执行完成。</li></ol><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>本文从再次提笔到今天写后记，总共用时 10个 自然日，篇幅已经很长了，要是再展开协程，不知道要写到什么时候。<br>正如参考视频开篇提到的，只有当自己亲自总结的时候，才会发现原来对相关知识还是理解太浅薄了。</p><p>这些天查了很多资料，也高强度请教 AI， 还动手写了很多古老的代码，工作间隙也在想如何举例，润色。</p><p>没有打游戏，少量刷视频，没想到还是做了不少东西。</p><p>上周五是我人生中有一个最低谷（或者专业点，极低谷）的时候，想到放弃，想到逃避，压抑地话都说不出来。</p><p>好在开了个好头，希望我在之后的学习中能再接再厉，表现越来越好。</p><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hard 4. Median of Two Sorted Arrays -- 第一道Hard，做了5年。</title>
    <link href="/2022/05/29/leetcode/@2022_4_hard%E4%B8%AD%E4%BD%8D%E6%95%B0/"/>
    <url>/2022/05/29/leetcode/@2022_4_hard%E4%B8%AD%E4%BD%8D%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我最重要的一道题，第一次遇到看题解也无法理解的题，想起了以前高中去竞赛划水的日子，想起了在大学划水地没有去竞赛的日子。</p><p>第一次看到这个题的时候，我还不知道做工程分前端和后端，我还可能只有170斤，我还看着Java代码觉得太丑陋看不懂；</p><p>后来小付快速的把这题理解并做出来了，我还是没有足够的行动力，后来就开始了一系列的迷茫的日子；</p><p>这么多年过去了，只有山东大哥的红轴Cherry键盘一直陪着我，他拿这键盘打Dota，考研；我拿这把键盘打Lol，假装考研；又在磨子桥的电脑城被我的老乡阵修理+魔改；然后在成都摸鱼，在深圳打字。</p><p>有很多变化了，又有很多没有变，不过看样子我的行动力确实螺旋上升了。</p><span id="more"></span><h1 id="题干"><a href="#题干" class="headerlink" title="题干"></a>题干</h1><p><a href="https://leetcode.com/problems/median-of-two-sorted-arrays/">https://leetcode.com/problems/median-of-two-sorted-arrays/</a></p><p>There are two sorted arrays nums1 and nums2 of size m and n respectively.</p><p>Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).</p><p>You may assume nums1 and nums2 cannot be both empty.</p><p>Example 1:</p><p>nums1 &#x3D; [1, 3]<br>nums2 &#x3D; [2]</p><p>The median is 2.0<br>Example 2:</p><p>nums1 &#x3D; [1, 2]<br>nums2 &#x3D; [3, 4]</p><p>The median is (2 + 3)&#x2F;2 &#x3D; 2.5</p><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><h2 id="保底算法"><a href="#保底算法" class="headerlink" title="保底算法"></a>保底算法</h2><p>先排序再找中位数，由于python的sort()使用的是快排，所以o(n)&#x3D;log(n)，不过揣摩出题人意图，肯定不是想考察这个知识点。</p><h2 id="分析类型"><a href="#分析类型" class="headerlink" title="分析类型"></a>分析类型</h2><p>分析之后不难得出，本题的目的是找出2个有规律的数组中的一个有特征的值，稍微思考之后能够得出可以用分治法；</p><p>原因为： 中位数实际上只与整个数组中位置最中间的两个数有关系，因此2个数组的共同中位数也只会与最多2数组中各取2个数（共计4个数）有关系，而其他部分都可以剪枝。</p><h1 id="分治法"><a href="#分治法" class="headerlink" title="分治法"></a>分治法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findMedianSortedArrays</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        nums1_small = nums2_small = <span class="hljs-number">0</span><br>        nums1_big = <span class="hljs-built_in">len</span>(nums1) - <span class="hljs-number">1</span><br>        nums2_big = <span class="hljs-built_in">len</span>(nums2) - <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">while</span> nums1_big - nums1_small + nums2_big - nums2_small &gt; <span class="hljs-number">2</span>:<br>            <span class="hljs-keyword">break</span>  <span class="hljs-comment"># TODO 一头一尾一个个删除</span><br><br>        <span class="hljs-comment"># 只剩下其中一个列表</span><br>        <span class="hljs-keyword">if</span> nums1_small &gt; nums1_big:<br>            <span class="hljs-keyword">return</span> (nums2[nums2_small] + nums2[nums2_big]) / <span class="hljs-number">2</span><br>        <span class="hljs-keyword">if</span> nums2_small &gt; nums2_big:<br>            <span class="hljs-keyword">return</span> (nums1[nums1_small] + nums1[nums1_big]) / <span class="hljs-number">2</span><br><br>        <span class="hljs-keyword">return</span> (<span class="hljs-built_in">max</span>(nums1[nums1_small], nums2[nums2_small]) + <span class="hljs-built_in">min</span>(nums1[nums1_big], nums2[nums2_big])) / <span class="hljs-number">2</span><br><br></code></pre></td></tr></table></figure><p>有了上述思路之后不难写出最初版本的伪代码：既找出分治原子，然后不断缩小问题规模；<br>体现在本题中就是：每次判断2数组两端4个数字，淘汰掉其中最大和最小的2数；然后当其中一个数组无法再淘汰数时</p><h2 id="分治原子有问题"><a href="#分治原子有问题" class="headerlink" title="分治原子有问题"></a>分治原子有问题</h2><p>跑了几个用例之后发现不正确，因为按照上述算法只有把其中一个数组中的数全部淘汰完了才是分治原子，这是不符合中位数定义的，因为每一个数组的最中间的2个数都是有成为“共同中位数”的可能的，因此分治原子条件应当是任意一个数字的长度小于2；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findMedianSortedArrays</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_mid</span>(<span class="hljs-params">nums</span>):<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> nums:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>            <span class="hljs-keyword">else</span>:<br>                len_nums = <span class="hljs-built_in">len</span>(nums)<br>                left = (len_nums - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span><br>                right = len_nums // <span class="hljs-number">2</span><br>                <span class="hljs-keyword">return</span> (nums[left] + nums[right]) / <span class="hljs-number">2</span><br><br>        len1 = <span class="hljs-built_in">len</span>(nums1)<br>        len2 = <span class="hljs-built_in">len</span>(nums2)<br>        <span class="hljs-keyword">while</span> len1 &gt; <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> len2 &gt; <span class="hljs-number">2</span>:<br>            <span class="hljs-keyword">pass</span>  <span class="hljs-comment"># TODO 一头一尾一个个删除</span><br>        <span class="hljs-keyword">if</span> len1 == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> get_mid(nums2)<br>        <span class="hljs-keyword">if</span> len2 == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> get_mid(nums1)<br>        <br>        <span class="hljs-comment"># TODO 解决其他分治原子问题</span><br><br>        <span class="hljs-keyword">return</span> get_mid(nums1)<br></code></pre></td></tr></table></figure><p>中间其实经过了长达一个星期的思考和尝试，在这里意义不大就不展开了，毕竟距离我第一次看这个题已经过去5年；</p><p>主要解决以下问题：</p><ol><li>摒弃中学时代的“下标处理数组模式”，都做了这么多年工程了，还是要明白可读性是远比”性能“重要的，且最后的时间表也看得出来并没有多少损耗；</li><li>优先处理特殊情况，这个从OJ到工程都是很重要的，这个都忘了那就没啥可说的了；</li><li>分治原子找错了，当其中任意一个数组只剩小于2个数的时候就可以结束分治进入决赛圈了；</li></ol><h2 id="分治原子的优化-O-n-的思辨"><a href="#分治原子的优化-O-n-的思辨" class="headerlink" title="分治原子的优化 &amp; O(n)的思辨"></a>分治原子的优化 &amp; O(n)的思辨</h2><p>在本来的做法中，进入决赛圈后，我是拿其中小的那个数组中剩下的数去和大的数字的两边，中间各个数字进行比较；</p><p>为此还总结了3种情况： 包含在大的中，分离在大的外，与大的交叉，然后又根据这三种情况进一步的分类，试图找出通用的比较规则；</p><p>实际上非常的蠢，是属于自己给自己找麻烦，且实际上的刷题过程中，经常由于这种case过多的情况进行放弃。</p><p>在连续想了一个星期之后，突然发现，对于分治原子来说，最后这一步使用的方法是不会影响到整体的时间复杂度的，且做了这么多年工程，熟练使用轮子的意义远大于反复的抠这几个下标，于是果断使用先合并、排序再找中位数的方法；</p><p>且由于最后决赛圈的中位数说白了还是在小于4个数之间出现，因此这一步O(n)&#x3D;1；</p><p>实际上很多时候思维是会被自己局限的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># TODO 解决其他分治原子问题 code</span><br>nums1.extend(nums2)<br>nums1.sort()<br><br><span class="hljs-keyword">return</span> get_mid(nums1)<br></code></pre></td></tr></table></figure><h2 id="分治策略的优化"><a href="#分治策略的优化" class="headerlink" title="分治策略的优化"></a>分治策略的优化</h2><p>跑几个case之后就会发现，实际上对一个数组来说，除了“中间”一点的位置可能产生中位数，其他部位其实都是炮灰；</p><p>再发现数组边上其实很多时候都是在重复淘汰同一边的数，在继续观察之后发现规律：</p><p>先比较两个数组的中位数，同时将2个数组平均分成两份，考虑一下，中位数只可能诞生在两个数组相对“中间”的位置，因此一次性淘汰掉2个数组的两边的部分；</p><p>最后再注意一下边界取值等，代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># TODO 一头一尾一个个删除</span><br>len1 = <span class="hljs-built_in">len</span>(nums1)<br>len2 = <span class="hljs-built_in">len</span>(nums2)<br><span class="hljs-keyword">while</span> len1 &gt; <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> len2 &gt; <span class="hljs-number">2</span>:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(nums1) == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(nums2) == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">break</span><br><br>    mid_1 = get_mid(nums1)<br>    mid_2 = get_mid(nums2)<br>    <span class="hljs-keyword">if</span> mid_1 == mid_2:<br>        <span class="hljs-keyword">return</span> mid_1<br>    <span class="hljs-keyword">elif</span> mid_1 &lt; mid_2:  <span class="hljs-comment"># 砍掉nums1小的和nums2大的部分</span><br>        cut = <span class="hljs-built_in">min</span>((<span class="hljs-built_in">len</span>(nums1) - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span>, (<span class="hljs-built_in">len</span>(nums2) - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span>)<br>        nums1 = nums1[cut:]<br>        nums2 = nums2[:len2 - cut]<br>    <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 砍掉nums1大的和nums2小的部分</span><br>        cut = <span class="hljs-built_in">min</span>((<span class="hljs-built_in">len</span>(nums2) - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span>, (<span class="hljs-built_in">len</span>(nums1) - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span>)<br>        nums1 = nums1[:len1 - cut]<br>        nums2 = nums2[cut:]<br>    len1 = <span class="hljs-built_in">len</span>(nums1)<br>    len2 = <span class="hljs-built_in">len</span>(nums2)<br><br></code></pre></td></tr></table></figure><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10/dist/style.css"><script src="https://fastly.jsdelivr.net/npm/d3@7"></script><script src="https://fastly.jsdelivr.net/npm/markmap-view@0.18.10"></script><script src="https://fastly.jsdelivr.net/npm/markmap-toolbar@0.18.10"></script><link rel="stylesheet" href="/css/markmap.css"><script src="/js/markmap.js"></script>]]></content>
    
    
    <categories>
      
      <category>Leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hard</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
